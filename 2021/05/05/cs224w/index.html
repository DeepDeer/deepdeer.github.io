<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/deer-icon.png">
  <link rel="icon" type="image/png" href="/img/deer-icon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#87847e">
  <meta name="description" content="">
  <meta name="author" content="Skyla Sun">
  <meta name="keywords" content="">
  <title>cs224w《图机器学习》2021（一）经典方法 - DeepDeer</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/gitalk/1.6.2/gitalk.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 40vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>日言寺青</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/fav.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
                cs224w《图机器学习》2021（一）经典方法
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2021-05-05 14:37">
      2021年5月5日 下午
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      3.8k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      44
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <h2 id="学习资料"><a class="markdownIt-Anchor" href="#学习资料"></a> 学习资料</h2>
<p>相比于2019年的课堂录播，本年度直接使用线上课程形式，更加方便理解学习。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/dagang.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<p>课程官方网站：<a href="http://web.stanford.edu/class/cs224w/" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224w/</a></p>
<p>课程视频链接：Youtube（<a href="https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn%EF%BC%89%E3%80%81B%E7%AB%99%EF%BC%88https://www.bilibili.com/video/BV1RZ4y1c7Co%EF%BC%89" target="_blank" rel="noopener">https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn）、B站（https://www.bilibili.com/video/BV1RZ4y1c7Co）</a></p>
<p>参考书目：《Graph Representation Learning 》by Will Hamilton</p>
<p>编程工具：<a href="https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html" target="_blank" rel="noopener">Pytorch Geometric（PyG）</a>、DeepSNAP、GraphGym、<a href="http://SNAP.PY" target="_blank" rel="noopener">SNAP.PY</a>、<a href="https://networkx.org/documentation/stable/tutorial.html" target="_blank" rel="noopener">NetworkX</a></p>
<h3 id="相关论文"><a class="markdownIt-Anchor" href="#相关论文"></a> 相关论文</h3>
<ul>
<li>PinSAGE，《Graph Convolutional Neural Networks for Web-Scale Recommender Systems》KDD，2018</li>
<li>DeepWalk, 《Online Learning of Social Representations》KDD 2014</li>
<li>node2vec，《node2vec: Scalable Feature Learning for Networks.》KDD 2016</li>
<li>Graph Embedding Survey，《Graph Embedding Techniques, Applications, and Performance: A Survey》2017</li>
<li>子图表征，引入虚拟节点，《Gated Graph Sequence Neural Networks》</li>
<li>匿名游走，《Anonymous Walk Embeddings》ICML 2018</li>
<li>矩阵分解与节点表征，《Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec》WSDM 2018</li>
</ul>
<h2 id="背景"><a class="markdownIt-Anchor" href="#背景"></a> 背景</h2>
<p>为什么使用图模型？</p>
<p>不仅考虑数据本身，还要考虑实体间的复杂关系。How do we take advantage of relational structure for better prediction?</p>
<p>多种图模型样例：计算机网络、疾病传播、食物链网络、交通网络、社交网络、论文引用、神经元连接、知识图谱、代码、化学分子、3D建模等等。</p>
<p>当前深度学习模型一般应用于序列、图片等简单的数据结构。Graphs are the new frontier of deep learning.</p>
<p>图模型常见任务：</p>
<ul>
<li>节点分类：DeepMind提出AlphaFold解决生物学领域蛋白质折叠问题；蛋白质序列中的氨基酸为节点，氨基酸（残基）之间的接近度为边；</li>
<li>链路预测：推荐系统（users-items）、多种药物一起的副作用预测</li>
<li>图/子图分类：交通流量预测、药物发现</li>
<li>聚类</li>
<li>生成图：新分子发现</li>
<li>图进化：物理仿真</li>
</ul>
<p>选择节点和连接，构成何种图模型这一步非常重要。</p>
<p>图模型基础概念：</p>
<ul>
<li>有向、无向图  -&gt; 度、节点平均度（2E/N）</li>
<li>Bipartite Graph（二部图）-&gt; Folded network（映射图）</li>
<li>邻接矩阵（Adjacency Matrix），现实网络的邻接矩阵通常非常稀疏</li>
<li>边缘列表（Edge list），在深度学习工程实现时十分常用</li>
<li>邻接表（Adjacency list）</li>
<li>其它可用属性：边权重、排名、类型、标签以及其它与场景契合的属性等</li>
<li>自环（self-loops）</li>
<li>多图（multigraph）：一对节点间有多个边</li>
<li>连通性、强连接（有向图中每对节点可以相互访问，SCCs，Strongly connected components，强连接部分）、弱连接</li>
</ul>
<h2 id="经典图机器学习方法"><a class="markdownIt-Anchor" href="#经典图机器学习方法"></a> 经典图机器学习方法</h2>
<p>经典机器学习方法重点在于<strong>提取有效特征</strong>（hand-designed features）。</p>
<h3 id="一-特征提取"><a class="markdownIt-Anchor" href="#一-特征提取"></a> 一. 特征提取</h3>
<h4 id="1-node-features"><a class="markdownIt-Anchor" href="#1-node-features"></a> 1. Node features</h4>
<p><strong>节点度（node degree）</strong>[importance, structure]，相同度数的节点无法区分</p>
<p><strong>节点中心度（node centrality）</strong>[importance]，考虑了图中不同节点的重要程度，包括engienvector centrality，betweenness centrality, closeness centrality等。<strong>engienvector centrality</strong>，某节点的重要程度是其邻居节点重要程度的归一化和（递归计算）；<strong>betweenness centrality</strong>，存在于其它节点对间最短路径上的节点更重要；<strong>closeness centrality</strong>，与其它各节点间最短路径长度和越短的节点越重要。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/ec.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<div align="center">
  <img src="/2021/05/05/cs224w/bc.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<div align="center">
  <img src="/2021/05/05/cs224w/cc.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p><strong>聚类系数（clustering coefficient）</strong>[structure]，节点附近的局部结构，衡量某节点的邻居节点间的联通程度如何。基本上是在计算自网络（ego-network）中的<strong>三角形</strong>个数。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/coefficient.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p><strong>GDV(graphlet degree vector)</strong> [structure]，将上述三角形概念扩大，Rooted connected non-isomorphic subgraphs。以下概念中节点的位置也很重要。GDV即该节点在某种graphlet出现的次数。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/graphlets.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<div align="center">
  <img src="/2021/05/05/cs224w/gdv.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<h4 id="2-link-prediction-features"><a class="markdownIt-Anchor" href="#2-link-prediction-features"></a> 2. Link Prediction features</h4>
<p>链路预测任务，比如随机丢失了当前图模型中的某些连接信息，或需要预测下一时间窗口中的节点连接信息。</p>
<p><strong>Distance-based features</strong>，如两节点之间的最短距离</p>
<p><strong>Local neighborhood overlap</strong>，两节点间的共有邻居数，Jaccard系数、Adamic-Adar index等</p>
<p><strong>Global Neighborhood Overlap</strong>，katz index计算一对节点间的全部路径数目（使用邻接矩阵A计算）；邻接矩阵的N次幂表示了每对节点间长度为N的路径的数量。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/katz.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<h4 id="3-graph-level-features"><a class="markdownIt-Anchor" href="#3-graph-level-features"></a> 3. Graph-level features</h4>
<p>核方法（kernel），核心是设计一个kernel而不是使用特征向量。两个图模型之间的Kernel衡量的是图数据之间的相似度。内核矩阵是测量每对数据点之间的相似度，它一定是正定的，即只有正数特征值。</p>
<p>当前存在很多Graph kernels，比如graphlet kernel，Weisfeiler-Lehman Kernel, Random-walk kernel，shortest-path graph kernel等等。</p>
<p>Graph kernel背后的思想是给图模型做词袋（Bag-of-words），将图中的节点视为词，比如Bag of node degrees。而graphlet kernel，Weisfeiler-Lehman Kernel是这类方法的延伸，即使用了比节点度更复杂一些的表示方法。</p>
<p>Graphlet kernel使用不同graphlet数目，这边的graphlet定义与node-level features那一节中的有所不同。首先这类graphlet中允许存在孤立节点，而且它们不是rooted。注意，计算两个图模型相似性的时候可以把向量f归一化一下。这类方法的问题在于graphlets计数非常困难，类似的subgraph isomorphism test问题是NP难的。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/graphlet.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p><strong>Weisefeiler-Lehman Kernel</strong>旨在缓解这个问题，使用<strong>color refinement</strong>。其中确定属性使用到了哈希函数。这个方法计算效率较高，是线性于两个图的边数目的。Weisefeiler-Lehman Kernel是衡量图相似度的一种非常有效的方式（很难被击败），也是与GNN是息息相关的。</p>
<h2 id="节点表征"><a class="markdownIt-Anchor" href="#节点表征"></a> 节点表征</h2>
<p>重点包括三部分内容：1）编解码器框架，encoder是一个简单的表征向量查询，decoder是基于表征向量计算与定义的节点相似度匹配程度；2）节点相似度衡量方法：基于随机游走；3）图级别表征方法，可以直接将节点表征向量聚合或者利用匿名游走。</p>
<h3 id="一-encoder-decoder-框架"><a class="markdownIt-Anchor" href="#一-encoder-decoder-框架"></a> 一. Encoder + Decoder 框架</h3>
<p>相较于传统的图学习方法，图表征学习省去了特征工程的步骤，直接自动学习图特征，之后应用于不同下游任务。</p>
<p>Efficient task-independent feature learning for machine learning with graphs. Encode nodes so that similarity in the embedding space (e.g., dot product) approximates similarity in the graph.</p>
<p>重点在于定义：1）什么是图上的节点相似性；2）节点到向量的映射函数。</p>
<p>一个最简单的encoder（shallow encoder）就是对于embeddings的查询。我们可以去直接优化每个节点的表征向量。但如果是大图的话，这个方法会很慢，因为嵌入矩阵Z会有很多列，要针对每一个进行表征向量估计。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/embedding.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>如何衡量图中节点相似度？这也是不同算法工作中比较大的差异点。大多流行方法会使用<strong>随机游走</strong>。</p>
<p>节点表征方法的特点：</p>
<ul>
<li>这类方法属于无监督或自监督学习，并没有利用到标签信息</li>
<li>没有利用节点属性，方法的目标是表征向量体现出图结构信息</li>
<li>表征结果是独立于下游任务的</li>
</ul>
<h3 id="二-基于random-walk的节点表征方法"><a class="markdownIt-Anchor" href="#二-基于random-walk的节点表征方法"></a> 二. 基于Random Walk的节点表征方法</h3>
<p>关于图中节点间的相似度衡量定义为两节点同时出现在图中统一随机游走记录中的概率。</p>
<p>使用随机游走的优势在于：1）可以同时考虑局部和高阶邻居信息；2）只需要考虑在随机游走中同时出现的节点对，而不是考虑图上的全部节点对。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/rw.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>一般会在某些游走策略R下使用short fixed-length随机游走，收集某节点的邻居节点集合（此集合为multiset，即允许重复，因为某些节点可以被访问多次），之后调整嵌入向量z（参数）去优化最大似然概率。下图使用了softmax方法。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/rwe.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>但直接进行这样的计算代价很大，复杂度是图中节点数的平方。我们同样使用<strong>负采样（negative sampling）<strong>进行优化，只在负样本集合上计算而非在全部数据上计算。那么</strong>如何选取负样本</strong>呢？采样概率依照每个不同节点的度设定，共采样K个。K值越高得到的模型越鲁棒，但同时对负样本的偏向也越高，实际中<strong>一般选取K=5-20</strong>。</p>
<p>最后使用梯度下降方法优化即可。</p>
<p>最后一个问题是<strong>如何设定随机游走策略</strong>？最简单的方法是直接进行fixed-length, unbiased random walks（DeepWalk使用）。而node2vec认为更灵活地定义邻居节点可以获取包含信息量更大的节点表征，所以提出了biased 2nd order随机游走来生成节点邻居集合，这个方法可以综合权衡局部（BFS）和全局（DFS）信息。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/node2vec.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>因此node2vec提出return参数p（返回到之前的节点）和in-out参数q（BFS和DFS的比例）。关键在于<strong>记录了上一节点信息</strong>，对于处于某个节点的随机游走，下一节点有三种选择：1）退回上一节点；2）去和上一节点距离相同的节点；3）去距离上一节点更远的节点。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/pq.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>Node2vec算法总结如下，算法为<strong>线性复杂度</strong>，三个步骤可以并行处理。</p>
<ul>
<li>计算随机游走概率</li>
<li>对每个节点u模拟r次长度为l的随机游走</li>
<li>使用随机梯度下降法优化目标函数</li>
</ul>
<p>还有很多<strong>其它经典算法</strong>应用了不同的随机游走策略、优化策略和一些数据预处理技巧。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/others.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<p>截至目前，我们学习了三类图中<strong>节点相似度度量</strong>的方法：</p>
<ul>
<li>Naive：有连接的节点相似；</li>
<li>第二节中的Neighborhood overlap，即两节点间共有邻居情况</li>
<li>基于随机游走的节点向量表征</li>
</ul>
<p><strong>Must choose definition of node similarity that matches your application!</strong></p>
<h3 id="三-图表征"><a class="markdownIt-Anchor" href="#三-图表征"></a> 三. 图表征</h3>
<p>图或子图级别（即多个节点）的向量表征。</p>
<p>方法一：最简单是沿用节点向量表征方法，之后直接加和或平均，作为整个图的表征向量，虽然简单但是实际效果还不错。也可以使用层次聚类的方法逐步计算。</p>
<p>方法二：引入一个虚拟节点“virtual node”代表整个图/子图。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/subgraph.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p><strong>方法三</strong>：使用<strong>匿名游走（anonymous walks）</strong>，名字由来在于最终结果与具体图中节点信息无关。随着随机游走长度的增长，匿名游走数量呈指数型增长。可以按不同长度L匿名游走下不同游走类型的数量/概率作为表征向量。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/aw.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>如何确定我们需要的匿名游走的数量？</p>
<div align="center">
  <img src="/2021/05/05/cs224w/count_aw.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>以同时出现在时间窗口T中的匿名游走为样本进行训练。这也是和DeepWalk之间的一大差异，即没有用节点集合左右邻居域。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/awe.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<div align="center">
  <img src="/2021/05/05/cs224w/awg.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<h2 id="pagerank一些链路分析方法"><a class="markdownIt-Anchor" href="#pagerank一些链路分析方法"></a> PageRank（一些链路分析方法）</h2>
<p>从矩阵角度进行图数据分析，由此可以进行：1）基于随机游走衡量节点重要程度（PageRank）；2）通过矩阵分解（Matrix factorization，MF）获取节点向量表征；3）将其它节点向量表征视为MF。</p>
<p><strong>Random walk，matrix factorization and node embeddings are closely related!</strong></p>
<div align="center">
  <img src="/2021/05/05/cs224w/summary.png" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>之前的假设是把互联网中的（静态）网页视为节点，超链接视为边，去<strong>衡量网页的重要性</strong>。[ 虽然目前随着互联网的发展有了很多<strong>动态页面</strong>以及一些<strong>无法访问的生成页面</strong>。之前的网站链接多为navigational，而如今的更多是transactional。]</p>
<h4 id="1-pagerank"><a class="markdownIt-Anchor" href="#1-pagerank"></a> 1. PageRank</h4>
<p>将网页链接视为投票，使用in-links权衡，但每个连接的重要程度又不同，从而形成一个递归问题。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/page.jpg" srcset="/img/loading.gif" width="20%" height="20%" alt="oauth">
</div>
<p>计算使用<strong>列随机矩阵M</strong>，最终得到<strong>秩向量r</strong>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mo>=</mo><mi>M</mi><mo separator="true">⋅</mo><mi>r</mi></mrow><annotation encoding="application/x-tex">r = M · r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span></span></span>。可以将r视作<strong>随机游走</strong>收敛到的平稳分布，或者<strong>视为M的特征值为1对应的特征向量</strong>，即主特征向量。它是随机游走方程、基于流的方程式 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo separator="true">⋅</mo><mi>r</mi><mo>=</mo><mi>M</mi><mo separator="true">⋅</mo><mi>r</mi></mrow><annotation encoding="application/x-tex">1·r = M · r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span></span></span>和线性代数的特征向量、特征值的完美融合。</p>
<p>[ 这里与前文中介绍的节点中心度中的<strong>eignvector centrality</strong>（针对无向图）和<strong>Katz centrality</strong>有一些梦幻联动。]</p>
<div align="center">
  <img src="/2021/05/05/cs224w/pc.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>使用幂迭代（power iteration）方法求解r，一般来讲迭代50次会大致收敛。[ 下图中左右两侧的迭代公式意义相同 ]</p>
<div align="center">
  <img src="/2021/05/05/cs224w/pi.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>还有<strong>两个问题</strong>需要关注：</p>
<p>第一，死胡同问题（dead ends）[数学问题]，有的页面时没有out-link的。解决方法是，给没有out-link的页面所在的M列<strong>赋均值</strong>。</p>
<p>第二，蜘蛛陷阱（spider traps）[非数学问题]，有些页面相互连接，最终吸收了所有的“重要性”。解决方法是，引入参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span>，表示继续沿着当前link游走的概率，而有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>−</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">1-\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span>的概率**随机传送（teleport）**到任意页面，<strong>一般取值在0.8-0.9之间</strong>。</p>
<p>所以，Google的做法如下，或者写成矩阵形式<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi><mo>=</mo><mi>β</mi><mi>M</mi><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>β</mi><mo stretchy="false">)</mo><mo stretchy="false">⌈</mo><mstyle displaystyle="true" scriptlevel="0"><mfrac><mn>1</mn><mi>N</mi></mfrac></mstyle><msub><mo stretchy="false">⌉</mo><mrow><mi>N</mi><mo>×</mo><mi>N</mi></mrow></msub><mo separator="true">,</mo><mi>r</mi><mo>=</mo><mi>G</mi><mo>∗</mo><mi>r</mi></mrow><annotation encoding="application/x-tex">G = \beta M + (1-\beta) \lceil \dfrac{1}{N} \rceil_{N \times N},  r = G * r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">G</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mclose">)</span><span class="mopen">⌈</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="mclose">⌉</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">G</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span></span></span></p>
<div align="center">
  <img src="/2021/05/05/cs224w/google.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>我们虽然从随机游走的角度来理解算法，但运行过程中并不实际进行游走，而是假定它游走了无限长时间。</p>
<h4 id="2-personalized-pagerankppr-random-walk-with-restarts"><a class="markdownIt-Anchor" href="#2-personalized-pagerankppr-random-walk-with-restarts"></a> 2. Personalized PageRank（PPR）&amp; Random walk with restarts</h4>
<p>PPR：在传送的时候不像PageRank那样概率传送到图中每个节点而是只取<strong>一个节点子集S</strong>。这个子集由之前的随机游走记录而得，每个节点的概率由访问次数决定。</p>
<div align="center">
  <img src="/2021/05/05/cs224w/ppr.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>Random walk with restarts：将传送节点子集S缩小至单个节点，即总是传送回起始节点。</p>
<p>优势在于这类方法考虑了：1）一对节点间多种连接；2）多条路径；3）连接是否有向；4）路径中节点的度。</p>
<h4 id="3-矩阵分解与节点表征的关系"><a class="markdownIt-Anchor" href="#3-矩阵分解与节点表征的关系"></a> 3. 矩阵分解与节点表征的关系</h4>
<p>以“存在边连接”定义节点相似度的内积形式的解码器与邻接矩阵A的矩阵分解等价。</p>
<p>DeepWalk、node2vec等方法具有更为复杂的节点相似度定义（基于随机游走），它们等同于形式更为复杂的矩阵的矩阵分解。</p>
<p>下图为DeepWalk对应的矩阵形式：</p>
<div align="center">
  <img src="/2021/05/05/cs224w/DeepWalk.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<h4 id="4方法局限性"><a class="markdownIt-Anchor" href="#4方法局限性"></a> 4.方法局限性</h4>
<p>这类基于矩阵分解/随机游走的节点表征方法，如DeepWalk、node2vec等（PageRank也可以视为一维嵌入）有以下几点局限：</p>
<ul>
<li>
<p>无法得到新加入（未在训练集中出现过）的节点的表征向量；</p>
</li>
<li>
<p>无法捕获结构相似性（structurally similar），比如下图中节点1和节点11会有很不同的表征。如果使用匿名随机游走也许有提升；</p>
</li>
<li>
<p>无法利用节点、边或整个图的特征信息</p>
</li>
</ul>
<div align="center">
  <img src="/2021/05/05/cs224w/limit.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>针对以上这些缺陷的解决方法是：Deep Representation Learning和Graph Neural Networks。</p>
<h2 id="课程作业借鉴"><a class="markdownIt-Anchor" href="#课程作业借鉴"></a> 课程作业借鉴</h2>
<h4 id="1可视化函数"><a class="markdownIt-Anchor" href="#1可视化函数"></a> 1.可视化函数</h4>
<pre><code class="hljs python"><span class="hljs-comment"># Helper function for visualization.</span>
%matplotlib inline
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-comment"># Visualization function for NX graph or PyTorch tensor</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">visualize</span><span class="hljs-params">(h, color, epoch=None, loss=None)</span>:</span>
    plt.figure(figsize=(<span class="hljs-number">7</span>,<span class="hljs-number">7</span>))
    plt.xticks([])
    plt.yticks([])

    <span class="hljs-keyword">if</span> torch.is_tensor(h):
        h = h.detach().cpu().numpy()
        plt.scatter(h[:, <span class="hljs-number">0</span>], h[:, <span class="hljs-number">1</span>], s=<span class="hljs-number">140</span>, c=color, cmap=<span class="hljs-string">"Set2"</span>)
        <span class="hljs-keyword">if</span> epoch <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> loss <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:
            plt.xlabel(<span class="hljs-string">f'Epoch: <span class="hljs-subst">&#123;epoch&#125;</span>, Loss: <span class="hljs-subst">&#123;loss.item():<span class="hljs-number">.4</span>f&#125;</span>'</span>, fontsize=<span class="hljs-number">16</span>)
    <span class="hljs-keyword">else</span>:
        nx.draw_networkx(G, pos=nx.spring_layout(G, seed=<span class="hljs-number">42</span>), with_labels=<span class="hljs-literal">False</span>,
                         node_color=color, cmap=<span class="hljs-string">"Set2"</span>)
    plt.show()</code></pre>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E5%9B%BE%E6%A8%A1%E5%9E%8B/">图模型</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2021/05/06/cs224w2/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">cs224w《图机器学习》2021（二）图神经网络</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/12/22/limit-graph/">
                        <span class="hidden-mobile">图神经网络的局限</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    function loadGitalk(){
      addScript('https://cdn.staticfile.org/gitalk/1.6.2/gitalk.min.js', function () {
        var gitalk = new Gitalk({
          clientID: '719893e76127bcc98b08',
          clientSecret: 'ed167d3d935e2922b47f190e1f36b026bd823a2d',
          repo: 'deepdeer.github.io',
          owner: 'DeepDeer',
          admin: 'DeepDeer',
          id: location.pathname,
          language: 'zh-CN',
          perPage: 15,
          pagerDirection: 'last',
          createIssueManually: 'false',
          distractionFreeMode: 'false'
        });
        gitalk.render('gitalk-container');
      });
    }
    createObserver(loadGitalk, 'gitalk-container');
  </script>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>




















</body>
</html>
