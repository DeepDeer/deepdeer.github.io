<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/deer-icon.png">
  <link rel="icon" type="image/png" href="/img/deer-icon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#87847e">
  <meta name="description" content="">
  <meta name="author" content="Skyla Sun">
  <meta name="keywords" content="">
  <title>联邦学习基础知识梳理 - DeepDeer</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/gitalk/1.6.2/gitalk.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 40vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>深鹿计划</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/fav.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
                联邦学习基础知识梳理
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2021-07-01 16:14">
      2021年7月1日 下午
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      10.8k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      111
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <p>传统学习方法为<strong>集中式学习</strong>，将数据收集至服务端进行训练和预测，结果发送至客户端，但这会造成延时高、浪费终端设备资源、数据隐私风险大等问题。而如果将模型放到<strong>端侧</strong>，终端根据本地数据完成模型训练和预测又存在数据量少且无法利用其它用户数据信息的问题。故2016年由谷歌提出联邦学习。联邦学习（FL）是一种分布式学习框架，许多客户端（如移动设备、组织）在中央服务器（如服务提供商）的协调下<strong>共同训练模型</strong>，同时保护<strong>本地数据隐私</strong>。广泛来讲，联邦学习是为了解决<strong>数据孤岛</strong>问题。</p>
<p>目前联邦学习已成为一个比较热门的研究方向。作为一个研究方向，“联邦学习”概念很宽泛，经过这几年的研究其边界得到极大扩大。比如学习过程中的数据不均衡、数据非独立同分布（non-I.I.D）、设备不可靠、有限通信带宽等挑战。</p>
<h1 id="联邦学习"><a class="markdownIt-Anchor" href="#联邦学习"></a> 《联邦学习》</h1>
<p>在发展过程中，联邦学习的一些曾用名及相关领域有，面向隐私保护的机器学习（Privacy-Preserving Machine Learning）、面向隐私保护的深度学习（Privacy-Preserving Deep Learning）、协作式机器学习（Collaborative Machine Learning）、协作式深度学习（Collaborative Deep Learning）、分布式机器学习（Distributed MachineLearning）、分布式深度学习（Distributed Deep Learning） 、联邦优化（Federated Optimization）和面向隐私保护的数据分析（Privacy-Preserving Data Analytics）等。</p>
<p>联邦学习强调的核心理念是：<strong>数据不动模型动，数据可用不可见</strong>。联邦学习是利用分散在各参与方的数据集，通过隐私保护技术融合多方数据信息，协同构建全局模型的一种分布式训练方式。在模型训练过程中，模型的相关信息（如模型参数、模型结构、参数梯度等）能够在各参与方之间交换（交换方式可以是明文、数据加密、添加噪声等），但本地训练数据不会离开本地。</p>
<p>**可能存在联邦模型比集中式模型（理想模型）效果好的情况。**比如以下场景，部分客户端的数据质量非常差，集中式训练方法由于存在低质量的训练数据而质量糟糕；反而进行联邦训练时，会对本地情况进行考察，将异常客户端剔除，总体性能有所提升。</p>
<p>当前联邦学习的研究主要集中于提升安全性以及处理统计学难题、通信开销、滞留问题、容错性等方面，考虑安全框架、客户端污染等问题。目前常用平台有：</p>
<ul>
<li>FATE，微众银行，实现了一种基于同态加密和多方计算的安全计算协议，支持一系列的联邦学习架构和安全计算算法。</li>
<li>TFF，包含一个单机的实验运行模拟器。TFF接口由两层构成，联邦学习应用程序接口（Application ProgrammingInterface，API）和联邦学习核心API。</li>
<li>coMind关键组件是联邦平均算法的实现，搭建在TensorFlow的顶层并且提供实现联邦学习的高层API；</li>
<li>Horovod，由Uber创立，基于开放的消息传输接口（Message Passing Interface，MPI）支持联邦，工作在Tensorflow和Pytorch顶层，快速易用，目前还不支持加密方式。</li>
<li>OpenMined/PySyft提供了联邦学习和差分隐私。PySyft是PyTorch的一个简单外挂扩展。</li>
</ul>
<p><strong>根据样本和特征重叠程度不同</strong>，联邦学习可以分为，横向联邦学习（Horizontal FederatedLearning，HFL），纵向联邦学习（Vertical Federated Learning，VFL），联邦迁移学习（Federated Transfer Learning，FTL）。横向联邦学习也叫作基于样本划分的联邦学习，纵向联邦学习称为基于特征划分的联邦学习。联邦迁移学习适用于参与方的数据样本和数据特征都很少重叠的情况，特别适合处理<strong>异构数据的联邦问题</strong>。</p>
<ul>
<li>横向联邦，研究最多，常用于跨设备端的场景，当前线性模型、GBDT、RNN、CNN、横向矩阵分解等方法已经实现。基本上使用梯度下降等最优化算法的模型都能使用横向框架学习；</li>
<li>纵向联邦，常用于跨机构场景，当前线性模型、SecureBoost、神经网络、纵向矩阵分解、纵向因子分解机等都已经实现；</li>
<li>联邦迁移学习，强调在异构特征分布的多方场景下协同训练，当前研究较少，但应该是个热点。</li>
</ul>
<p>FL最常见的应用案例是在商业银行检测多方借贷活动，通过联邦学习，不再需要建立一个中央数据库。联邦迁移学习适用于金融场景中的风控建模，比如小微企业成立时间短，在信贷业务应用中存在数据稀缺、不全面、历史信息沉淀不足等问题，可以依据金融机构在中大型企业的信贷模型，将知识迁移到当前的小微企业中。</p>
<p><strong>根据各模型协调方式不同</strong>，可以分为集中式拓扑和对等网络拓扑。前者存在一个中心计算方负责收集模型信息并整合，易于设计和实现；后者则各方平等。</p>
<h2 id="一-隐私安全与机器学习"><a class="markdownIt-Anchor" href="#一-隐私安全与机器学习"></a> 一. 隐私安全与机器学习</h2>
<p><strong>面向隐私保护的机器学习（PPML</strong>），指使用了保护用户隐私和数据安全的防御技术的机器学习。2018年是其技术重大突破的一年。</p>
<p>与安全机器学习（Secure ML）中攻击者违反ML系统的完整性和可用性不同，PPML中攻击者违反了系统的隐私性和机密性。</p>
<ul>
<li>完整性，攻击导致ML系统检测错误，比如入侵检测为正常（假阴性）；</li>
<li>可用性，攻击导致出现分类错误（假阴性和假阳性），即系统不可用；</li>
<li>机密性，ML系统中的一些敏感信息（训练集或训练模型）泄露；</li>
</ul>
<div align="center">
  <img src="/2021/07/01/fl/sec.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<p>一个ML系统可以分成数据发布、模型训练和模型推理阶段。数据发布阶段可能发生特征推理攻击（Attribute-Inference Attacks）。模型训练阶段可能发生<strong>重构攻击（Reconstruction Attacks）</strong>，目的是重构数据提供者的原始数据，或者学习关于数据的更多信息，而不是最终模型所提供的信息。模型推理阶段可以实施<strong>模型反演攻击（Model Inversion Attacks）<strong>或</strong>成员推理攻击（Membership-InferenceAttacks）</strong>。<strong>重构攻击是联邦学习的主要隐私关注点。</strong></p>
<ul>
<li>重构攻击，如果数据结构是已知的，梯度信息可能也会被利用，从而泄露关于训练数据的额外信息。为了抵御重构攻击，应当避免使用存储显式特征值的机器学习模型。模型训练过程中，安全多方计算和同态加密可以被用来通过保护计算中间结果来抵御重构攻击。</li>
<li>模型反演攻击，目的是从模型中抽取训练数据或训练数据的特征向量。应当向敌手暴露尽可能少的关于模型的信息，比如仅仅返回舍入后的预测值，同态加密的贝叶斯神经网络等；</li>
<li>成员推理攻击，敌手对模型至少有黑盒访问权限，同时拥有一个特定的样本作为其先验知识。敌手的目标是判断模型的训练集中是否包含特定的样本。</li>
<li>特征推理攻击，敌手出于恶意目的，将数据去匿名化或锁定记录的拥有者；有文献提出群组匿名化技术，通过泛化（generalization）和抑制（repression）机制抵抗这种攻击。</li>
</ul>
<p>对于攻击者我们通常认为他是<strong>半诚实的</strong>，即遵守协议，但也会试图从接收到的信息中学习更多除输出以外的信息。在密码学中，通常会首先建立一个针对半诚实的敌手的安全协议，然后通过零知识证明（zero-knowledge proof）对其进行加强，进而防御恶意的敌手的攻击。</p>
<blockquote>
<p>半诚实，诚实但好奇的</p>
</blockquote>
<p>对于每个安全模型，敌手会攻击一部分参与方使之腐败，而腐败的参与方可能相互勾结。参与方的腐败可以<strong>是静态的（static）</strong>，也可以是<strong>自适应的（adaptive）</strong>。敌手的复杂度可以是<strong>多项式时间（polynomial-time）的或无计算界限（computational unbounded）<strong>的，分别对应</strong>计算安全和信息理论安全</strong>。</p>
<h3 id="1-安全多方计算"><a class="markdownIt-Anchor" href="#1-安全多方计算"></a> 1. 安全多方计算</h3>
<p>对于任何功能需求，我们都可以在不必显示除了输出以外的前提下计算它。</p>
<p>通常情况下，安全多方计算能够通过三种不同的框架来实现：不经意传输（Oblivious Transfer，OT）、秘密共享（Secret Sharing，SS）和阈值同态加密（Threshold Homomorphic Encryption，THE）。<strong>秘密共享</strong>被广泛认为是安全多方计算的核心。</p>
<ul>
<li>不经意传输常见构造方法有，Bellare-Micali构造、Naor-Pinka构造以及Hazay-Lindell构造；姚氏混淆电路；不经意传输扩展。</li>
<li>秘密共享是指通过将秘密值分割为随机多份，并将这些份（或称共享内容）分发给不同方来隐藏秘密值；Shamir秘密共享基于多项式构建，其它还有算数秘密共享（安全乘法三元组）、二进制秘密共享。</li>
</ul>
<p>在PPML中的应用包括DeepSecure、SecureML、Chameleon和ID3。</p>
<h3 id="2-同态加密"><a class="markdownIt-Anchor" href="#2-同态加密"></a> 2. 同态加密</h3>
<p>同态加密（HE）是一种允许对密文进行计算操作并生成加密结果的加密技术。在密文上获得的计算结果被解密后与在明文上的计算结果相匹配，就如同对明文执行了一样的计算操作。</p>
<p>同态加密方案H由一个四元组组成，包括KeyGen（密钥生成函数），Enc（加密函数），Dec（解密函数）和Eval（评估函数）。</p>
<p>加法和乘法。</p>
<p>同态加密分为部分同态加密（Partially Homomorphic Encryption，进行加法或乘法），些许同态加密（Somewhat Homomorphic Encryption，进行有限次）和全同态加密（Fully Homomorphic Encryption，进行无限次）。许多研究人员目前正着眼于发现满足特定需求的、更有效的SHE方法，而非去发掘FHE方法。</p>
<p>在PPML中的应用包括CryptoNets、CryptoDL、GAZELLE、FedMF等。</p>
<h3 id="3-差分隐私"><a class="markdownIt-Anchor" href="#3-差分隐私"></a> 3. 差分隐私</h3>
<p>函数的输出结果对数据集中的任何特定记录都不敏感。因此，差分隐私能被用于抵抗成员推理攻击。中心思想是混淆数据，使得敌手无法从查询结果中辨别个体级别的敏感性。</p>
<p>差分隐私在向数据引入噪声的同时，权衡了实用性和隐私性。现有的机器学习差分隐私机制很少能达到较好的平衡。</p>
<p>加入噪声有两种方法，一种是根据函数的敏感性（可表示添加或删除单个样本，函数值可能发生变化的最大程度），一种是根据离散值的指数分布（指数机制，质量函数q）。</p>
<p>根据噪声添加的位置，可以分为输入扰动、目标扰动、算法扰动和输出扰动。</p>
<p>联邦学习中可以使用本地差分隐私（LDP），每一个输入方扰乱自己的数据，然后将已混淆的数据发布至不受信任的服务器。中心思想是<strong>随机回应（Randomized Response，RR）</strong>。</p>
<p>Moments accountant算法，Papernot等人的工作，基于差分隐私的LSTM，使用GAN生成差分隐私数据集。</p>
<h2 id="二-分布式机器学习dml"><a class="markdownIt-Anchor" href="#二-分布式机器学习dml"></a> 二. 分布式机器学习（DML）</h2>
<p>分布式机器学习也称为分布式学习，是指利用多个计算节点（也称为工作者，Worker）进行机器学习或者深度学习的算法和系统，旨在提高性能、保护隐私，并可扩展至更大规模的训练数据和更大的模型。</p>
<p>DML可以分为两类：面向扩展性的DML（Scalability-MotivatedDML）和面向隐私保护的DML（Privacy-Motivated DML）。</p>
<p><strong>面向扩展性的DML</strong>被广泛用于解决大规模机器学习问题中的计算资源和内存空间限制。<strong>并行技术</strong>（例如数据并行、模型并行和混合并行）是实现面向扩展性的DML系统的主要选择。</p>
<p><strong>面向隐私保护的DML</strong>主要用于保护用户隐私，并通过分散的数据存储来确保数据安全。安全多方计算、同态加密和差分隐私是面向隐私保护的DML系统里的常用隐私保护技术。</p>
<p>使用最广的DML数据处理系统之一是Apache Spark MLlib。基于图的并行处理算法是DML最近一个比较新的方法，GraphLab平台，另一个平台是Apache Spark GraphX。微软发布DMTK。其他DL框架，如TensorFlow、PyTorch也都支持DNN的分布式训练和部署。</p>
<h3 id="1-面向扩展性的dml"><a class="markdownIt-Anchor" href="#1-面向扩展性的dml"></a> 1. 面向扩展性的DML</h3>
<p>常用的DML方案包括数据并行、模型并行、图并行、任务并行、混合并行和交叉并行。</p>
<p>**图并行（Graph Parallelism）方法，**也称为以图为中心的方法（Graph-CentricApproach），是一种用于划分和分配训练数据和执行ML算法的新技术，其执行速度比基于数据并行的方法要快几个数量级。</p>
<p>使用了任务并行的大数据计算框架有Apache Storm和Apache YARN。</p>
<h3 id="2-面向隐私的dml"><a class="markdownIt-Anchor" href="#2-面向隐私的dml"></a> 2. 面向隐私的DML</h3>
<p>一般被列为ML系统隐私的信息有，训练数据输入、预测标签输出、模型信息（包括模型参数、结构和损失函数）和身份识别信息（如记录的数据来源站点、出处或拥有者）。</p>
<p>不同于其他ML算法，数据的划分对于<strong>决策树</strong>来说是至关重要的，因为决策树的学习需要决定特征集合的划分，这取决于特征属性的类别以及在某一特定属性下的具有类标签的样本数量。</p>
<p>常用的用于保护数据隐私的方法大致分为：模糊处理（随机化、添加噪声或修改数据使其拥有某一级别的隐私，如差分隐私方法）和密码学方法（不以明文传输或不传输入值，比如安全多方计算）。但是，随机扰动影响了数据精度和模型性能。与基于扰动的方法相比，密码学方法并不需要牺牲数据精度和模型性能，但是需要更多的额外计算。</p>
<p>当前研究成果：一种基于差分隐私的隐私保护逻辑回归；面向隐私保护的支持向量机；深度学习模型中也有所使用；无监督学习；在FedAvg基础上进行秘密共享、不经意传输，并考虑了在一个沟通成本高昂、客户加入退出频繁的复杂移动环境下的使用；基于MPC的方法；</p>
<h4 id="面向隐私保护的梯度下降法"><a class="markdownIt-Anchor" href="#面向隐私保护的梯度下降法"></a> 面向隐私保护的梯度下降法</h4>
<p>包括朴素联邦学习（Naive FederatedLearning或者Vanilla Federated Learning）、代数方法、稀疏梯度更新方法、模糊处理方法和密码学方法（如同态加密和安全多方计算）。</p>
<ul>
<li>前三种，每一方发送给协调方明文形式的梯度信息以更新模型，而这只能保护数据的原始形式，即低隐私保护等级和非常高的效率；稀疏梯度更新方法还能通过更新梯度中的一个实体子集，用精度来换取效率和隐私；</li>
<li>模糊处理方法，基于随机化（加入噪声）、泛化或抑制机制（如梯度分层化、差分隐私、k-匿名方法）；</li>
</ul>
<p>朴素联邦学习法中，如果是纵向联邦，模型在各方间分配。梯度下降方法里，<strong>目标函数能被分解为一个可微函数和一个线性可分函数</strong>。每一方将自己的数据用于各自的局部模型，从而获得中间结果，并将其正常发送给协调方。协调方将所有中间结果积累起来，并评估可微函数以计算损失和梯度。最后，协调方更新整个模型，并将更新后的局部模型发送给每个相关方。</p>
<p><strong>联邦学习是DML的一种特殊类型。</strong></p>
<h3 id="三-横向联邦"><a class="markdownIt-Anchor" href="#三-横向联邦"></a> 三. 横向联邦</h3>
<p>当前有研究关注：在联邦学习框架下对用户模型更新或者对梯度信息进行安全聚合；适用于模型参数聚合的加法同态加密，防御系统里的中央服务器窃取模型信息或者数据隐私；多任务形式的系统，多个参与方通过分享知识和保护隐私的方式完成不同的机器学习任务，同时进一步解决通信开销大、网络延迟以及系统容错等问题；深度梯度压缩减少通信带宽；考虑恶意用户。</p>
<p>两种架构：客户-服务器架构和对等网络架构。如果联邦平均算法使用了安全多方计算或加法同态加密技术，则能防范半诚实的（semi-honest）服务器的攻击。</p>
<div align="center">
  <img src="/2021/07/01/fl/average.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<p>对等架构中，训练方们必须提前商定发送和接收模型参数信息的顺序，通常采用循环传输或随机传输（gossip学习）。</p>
<p>模型评估中，<strong>本地模型性能</strong>表示某一参与方在本地测试数据集上检验得出的横向联邦学习模型的性能，<strong>全局模型性能</strong>表示所有参与方在测试数据集上对横向联邦学习模型进行测试得出的模型性能。对等网络架构要得到全局模型性能将会更为复杂。一种可能的方式是选取某一个参与方来充当一个临时的协调方。</p>
<h4 id="1-fedavg介绍"><a class="markdownIt-Anchor" href="#1-fedavg介绍"></a> 1. FedAvg介绍</h4>
<p>为了区别于并行小批量随机梯度下降算法（parallel mini-batch SGD），联邦平均算法也被称为并行重启的随机梯度下降算法（parallel restarted SGD）或者local SGD。</p>
<p>相对于分布式优化问题，联邦优化有一些特性：</p>
<ul>
<li>数据集非独立同分布，不同参与方拥有的数据可能有着完全不同的分布；分布式学习中基本没有这个问题。</li>
<li>数据量不平衡，联邦学习的不同参与方通常拥有不同规模的训练数据集；</li>
<li>数量很大的参与方，分布式优化中并行工作机器的数量是可以轻易控制的，联邦学习则不然；</li>
<li>慢速且不稳定的通信连接，在数据中心里，人们期望计算节点彼此间能够快速通信，并且丢包率很低。然而，在联邦学习中，客户和服务器间的通信依赖于现有的网络连接。在FL中计算代价相比通信代价是微乎其微的。</li>
</ul>
<p>人们之前担心FedAvg不收敛，但最近的研究表明，充分参数化的DNN的损失函数表现得很好，特别是出现不好的局部极小值的可能性比以前认为的要小。<strong>Dropout训练方法的成功经验为联邦模型平均方法提供了一些直观的经验解释</strong>。</p>
<p>在此基础上，可以使用加法同态加密（AHE）如Paillier算法、基于带错误学习（Learning With Errors，LWE）的加密方法，来加强联邦平均算法的安全属性。使用AHE后，模型信息不会以明文形式传输，但加密操作和解密操作将会提高计算的复杂度，并且密文的传输也会增加额外的通信开销。而且为了评估非线性函数，需要使用多项式近似，引入精度和隐私性之间的权衡。</p>
<h4 id="2-fedavg改进"><a class="markdownIt-Anchor" href="#2-fedavg改进"></a> 2. FedAvg改进</h4>
<h5 id="提升通信效率"><a class="markdownIt-Anchor" href="#提升通信效率"></a> 提升通信效率</h5>
<p>压缩更新后的模型参数（通常是真正更新的无偏估计值），比如使用概率分层。</p>
<p>结构化参数更新，比如去除冗余、量化权重、哈夫曼编码以利用有效权重的偏倚分布等。</p>
<p>一种知名的梯度压缩方法是深度梯度压缩方法（DGC），动量修正、本地梯度截断、动量因子隐藏和预热训练。</p>
<p>如果仍然可以保证训练的收敛性，客户端也可以避免将不相关的模型更新上传到服务器，以降低通信开销。每个客户都检查其本地模型更新是否符合全局趋势，以及是否与全局模型改进足够相关。这样，每个客户端可以决定是否将其本地模型更新上传到服务器。</p>
<h5 id="参与方选择"><a class="markdownIt-Anchor" href="#参与方选择"></a> 参与方选择</h5>
<p>随机筛选出来的参与方发送资源查询消息，询问它们的本地资源以及与训练任务相关的数据规模。</p>
<p>协调方使用这些信息估计每一个参与方计算本地模型更新所需的时间，以及上传更新所需的时间，决定参与方。在给定一个全局迭代轮次所需的具体时间预算的情况下，协调方希望选择尽可能多的参与方。</p>
<h4 id="3-研究工作"><a class="markdownIt-Anchor" href="#3-研究工作"></a> 3. 研究工作</h4>
<p>通信开销问题是联邦学习系统面临的主要挑战之一，相关研究包括自适应通信策略AdaComm</p>
<p>解决IID问题的异步更新方法（《Asynchronous federatedoptimization》）。</p>
<p>一些研究工作希望去除可能会造成隐私泄露的协调方（中央服务器）。</p>
<p>具体应用中，首先是谷歌提出的移动终端应用的横向联邦学习进行输入预测，Gboard。</p>
<p>当前挑战如下：</p>
<ul>
<li>无法查看或者检查分布式的训练数据，很难选择机器学习模型的超参数以及设定优化器；</li>
<li>如何有效地激励公司和机构参与到横向联邦学习系统中来；</li>
<li>如何防止参与方的欺骗行为</li>
<li>由于模型的训练和评估在每一个参与方上都是本地进行的，我们需要发掘新的方法以避免过拟合以及触发提前停止训练</li>
<li>如何管理拥有不同可靠度的参与方</li>
</ul>
<h3 id="四-纵向联邦"><a class="markdownIt-Anchor" href="#四-纵向联邦"></a> 四. 纵向联邦</h3>
<p>数据集上具有相同的样本空间、不同的特征空间的参与方所组成的联邦学习归类为纵向联邦学习（Vertical Federated Learning，VFL）。横向联邦更多应用于B2C场景，纵向更多偏向B2B。</p>
<p>VFL系统的训练过程一般由两部分组成：1）对齐具有相同ID，但分布于不同参与方的实体；2）基于这些已对齐的实体执行加密的（或隐私保护的）模型训练。</p>
<p>架构中是否该保留一个受信任的第三方？</p>
<h4 id="1-安全联邦线性回归模型"><a class="markdownIt-Anchor" href="#1-安全联邦线性回归模型"></a> 1. 安全联邦线性回归模型</h4>
<div align="center">
  <img src="/2021/07/01/fl/char.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<div align="center">
  <img src="/2021/07/01/fl/proce.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<div align="center">
  <img src="/2021/07/01/fl/pred.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<h4 id="2-安全联邦提升树-secureboost"><a class="markdownIt-Anchor" href="#2-安全联邦提升树-secureboost"></a> 2. 安全联邦提升树 SecureBoost</h4>
<p>可以通过基于加密的数据库交集算法对样本进行对齐。</p>
<p>一项研究工作提出了角色区分，主动方（activeparty）不仅是数据提供方，同时拥有样本特征和样本标签，此外还扮演着协调者的角色，计算每个树节点的最佳分割；被动方（passive party）只是数据提供者，只提供样本特征，没有样本标签。</p>
<p>为了保证gi和hi的隐私性，主动方在将gi和hi发送给被动方之前，对梯度进行了加法同态加密。分割的评估将由主动方执行。</p>
<p>每一个被动方首先要对其所有的特征进行分桶，然后将每个特征的特征值映射至每个桶（buckets）中。基于分桶后的特征值，被动方将聚合相应的加密梯度统计信息。通过这种方法，主动方只需要从所有被动方处收集聚合的加密梯度统计信息。从而主动方可以更高效地确定全局最优分割。</p>
<p>在主动方得到全局最优分割之后，将特征id（kopt）和阈值id（vopt）返回给相应的被动方i。</p>
<div align="center">
  <img src="/2021/07/01/fl/securebost.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<p>预测过程中，新样本的特征也分散于各个参与方中，并且不能对外公开。分类过程从主动方的root节点开始。</p>
<ul>
<li>主动方查询与当前节点相关联的[参与方id，记录id]记录。基于该记录向相应参与方发送待标注样本的id和记录id，并且询问下一步的树搜索方向（即向左子节点或右子节点）</li>
<li>被动方接收到待标注样本的id和记录id后，将待标注样本中相应特征的值与本地查找表中的记录[记录id，特征，阈值]中的阈值进行比较，得出下一步的树搜索方向。然后，该被动方将搜索决定发往主动方。</li>
<li>主动方接收到被动方传来的搜索决定，前往相应的子节点。</li>
<li>迭代步骤1～3，直至到达一个叶节点得到分类标签以及该标签的权值。</li>
</ul>
<p>纵向联邦学习中各参与方彼此间有更紧密的共生关系。训练很容易受到通信故障的影响，从而需要可靠并且高效的通信机制。</p>
<p>目前，大部分防止信息泄露或者对抗恶意攻击的研究都是针对横向联邦学习的场景。由于纵向联邦学习通常需要参与方之间进行更紧密和直接的交互，因此需要灵活高效的安全协议，以满足每一方的安全需求。</p>
<h3 id="五-联邦迁移学习"><a class="markdownIt-Anchor" href="#五-联邦迁移学习"></a> 五. 联邦迁移学习</h3>
<p>异构联邦学习，参与方的数据集之间可能只有少量的重叠样本和特征，数据集的分布和数据量差异较大，而某些参与方可能只有数据，没有或只有很少的标注数据。</p>
<p>联邦迁移学习可以帮助只有少量数据（较少重叠的样本和特征）和弱监督（较少标记）的应用建立有效且精确的机器学习模型。</p>
<p>迁移学习主要分为三类：<strong>基于实例的迁移、基于特征的迁移和基于模型的迁移</strong>。联邦迁移学习将传统的迁移学习扩展到了面向隐私保护的分布式机器学习范式中。</p>
<ul>
<li>基于实例的联邦迁移学习，横向联邦中参与方可以<strong>有选择地挑选或者加权训练样本</strong>，<strong>以减小分布差异</strong>，从而可以将目标损失函数最小化；纵向联邦中，参与方可能具有非常不同的业务目标。对齐的样本及其某些特征可能对联邦迁移学习产生负面影响（<strong>负迁移</strong>），所以参与方可以<strong>有选择地挑选用于训练的特征和样本</strong>，以避免产生负迁移。</li>
<li>基于特征的联邦迁移学习，参与方协同学习一个**共同的表征（representation）空间，**缓解从原始数据转换而来的表征之间的分布和语义差异。对于横向联邦，可以最小化参与方样本之间的最大平均差异学习表征空间；对于纵向联邦，可以通过最小化对齐样本中属于不同参与方的表征之间的距离达到。</li>
<li>基于模型的联邦迁移学习，参与方利用<strong>预训练模型</strong>作为联邦学习任务的全部或者部分初始模型。横向联邦学习本身就是一种基于模型的联邦迁移学习。纵向联邦学习，可以从对齐的样本中学习预测模型或者利用半监督学习技术，以<strong>推断缺失的特征和标签</strong>。</li>
</ul>
<p>相较于传统的迁移学习，联邦迁移学习有如下特点：</p>
<ul>
<li>数据限制，基于分布在多方的数据来建立模型，并且每一方的数据不能集中到一起或公开给其他方。</li>
<li>要求对用户隐私和数据（甚至模型）安全进行保护</li>
</ul>
<p>一个多方的联邦迁移学习系统可以被认为是多个两方联邦迁移学习系统的结合。假设每一方都是诚实但好奇（honest-but-curious）的，即所有方都遵守联邦的协议和规则，但他们会尝试从收到的数据中推测出尽量多的信息。</p>
<p>联邦迁移学习系统的安全定义。</p>
<p>假设所有标签都在A方，可以使用基于加密（如RSA）的掩码技术，在保护隐私的同时，匹配A方和B方之间具有相同ID的样本。最终目标是双方协作地建立一个迁移学习模型，在不向对方公开数据的情况下，尽可能准确地为目标域中的B方预测标签。</p>
<p>有许多研究讨论了通过梯度传输而导致的间接隐私泄露的潜在风险，为了防止双方知道对方的梯度信息，A方和B方用加密的随机值进一步掩藏了各自的梯度，然后A方和B方交换加密的掩藏梯度和损失。</p>
<p>在安全联邦迁移学习中，性能损失的唯一来源是<strong>最终损失函数的泰勒二级近似</strong>，而不是在神经网络中的每个非线性激活层。</p>
<p>同态加密技术通常需要大量的计算资源和大规模的并行能力才能得以扩展，因此在许多需要实时计算的应用中，使用同态加密是不合适的。另一种安全协议是<strong>秘密共享（secret sharing scheme）</strong>，没有精度损失，计算效率大大提高，缺点是在进行线上计算之前，必须离线生成和存储许多用于乘法计算的三元组数据。</p>
<p>书中分别介绍了基于同态加密和秘密共享的联邦迁移学习的训练和预测过程。</p>
<p>当前联邦迁移学习面临的三个挑战：</p>
<ul>
<li>需要制定一种学习可迁移知识的方案。该方案能够很好地捕捉参与方之间的不变性。每一个参与方都对各自本地模型的设计和训练拥有完全的控制权。需要平衡自主性和泛化性。</li>
<li>需要精确地了解每一个参与方对共享表征作出的贡献，并考虑如何保护每个参与方所贡献信息的隐私安全；</li>
<li>设计能够部署在联邦迁移学习中的高效安全协议。</li>
</ul>
<h3 id="六-联邦强化学习"><a class="markdownIt-Anchor" href="#六-联邦强化学习"></a> 六. 联邦强化学习</h3>
<p>强化学习可以有如下分类：基于模型（首先尝试建立环境的虚拟模型）与无模型（通过反复迭代来修正价值函数和智能体策略）；基于价值（试图学习价值函数，找最优策略）和基于策略（从策略参数中进行搜索）；蒙特卡洛更新（通过使用整个周期内的积累奖励评估）与时间差分更新（价值函数的新估计值和旧估计值的差值）；在策略与离策略。</p>
<div align="center">
  <img src="/2021/07/01/fl/rl.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<p>分布式强化学习（Distributed Reinforcement Learning，DRL）在过去几十年得到了广泛的研究，但未涉及隐私保护问题。</p>
<p>大多数并行强化学习的设置采用的是迁移智能体经验或梯度的操作，但在隐私保护中是行不通的。HFRL应用并行强化学习应用的基础设置，并将隐私保护任务作为一项额外约束。</p>
<p>VFRL的一种可能的框架–联邦DQN（Federated DQN）。</p>
<h3 id="七-联邦学习激励机制"><a class="markdownIt-Anchor" href="#七-联邦学习激励机制"></a> 七. 联邦学习激励机制</h3>
<p>关键是制定一种奖励方法，公平公正地与参与方们分享联邦产生的利润。</p>
<p><strong>目标为</strong>最大化联邦的可持续性经营，同时最小化参与方间的不公平性，动态地将给定的预算分配给联邦中的各个参与方，还可以扩展为一种能够帮助联邦抵御恶意的参与方的调节机制。</p>
<p>通常使用的收益分享方法大致分为三类：</p>
<ul>
<li>平等，任何效用都平均分配；</li>
<li>边际效益，参与方的效益是它加入团队时所产生的效用；</li>
<li>边际损失，参与方的效益是它离开团队时所产生的效用；</li>
</ul>
<p>基于收益分享博弈法，反向拍卖，发布奖励（通过输出协议、信息论分析、<strong>模型改良</strong>等），纠正高估问题等方法。</p>
<p>设计激励机制的挑战在于：</p>
<ul>
<li>估计参与方加入联邦的代价成本；</li>
<li>如何估计参与方i对联邦做出的贡献；可以运行沙盒模拟。</li>
</ul>
<h3 id="八-应用场景"><a class="markdownIt-Anchor" href="#八-应用场景"></a> 八. 应用场景</h3>
<h4 id="1-cv"><a class="markdownIt-Anchor" href="#1-cv"></a> 1. CV</h4>
<p>分为目标检测、语义分割、运动跟踪、三维重建、视觉问答和动作识别等几个方面。</p>
<p>比如安装在人口密集区域如公园、购物广场及大学的摄像头组成联邦。本地目标检测模型被部署并开始工作。整个模型训练和部署过程都能以持续的方式执行，因为新的标注数据可以源源不断地加进来。</p>
<p>在医疗领域广泛用于疾病的诊断和预防。</p>
<p>为了加快训练过程，通常使用预训练模型来加速模型的收敛。然而，预训练机器学习模型与现有的联邦学习场景并不兼容。所以研发一种概率联邦学习框架，可以聚合预训练神经网络模型。更具体地说，其思想是跨客户匹配已训练的本地模型参数，以此构建全局模型。</p>
<p>最有可能发展的应用之一是基于分散在各种设备上的异构数据而构建的CV驱动自动驾驶系统。</p>
<p>联邦学习也对只有有限算力的用户设备带来了巨大挑战，1）开发专门用于DNN训练的硬件；2）促进如参数修剪、低秩分解、知识蒸馏等模型压缩技术的发展。</p>
<h4 id="2-nlp"><a class="markdownIt-Anchor" href="#2-nlp"></a> 2. NLP</h4>
<p>一个典型的应用场景是基于移动设备用户频繁键入的单词来学习词库外**（Out-of-Vocabulary，OOV）单词**。（这个可能要看一下）</p>
<p>唤醒词检测问题，唤醒词检测应用程序必须只消耗非常有限的能源预算，并且通常运行在内存和计算资源有限的微控制器上；而且需要有强鲁棒性。《Federated learning for keywordspotting》（ICASSP 2019），受到Adam[293]的启发，这一研究通过自适应平均策略优化了联邦平均算法解决数据non-IID、不平衡且高度分散的问题。</p>
<p>FetAtt方法，将注意力机制引入移动键盘输入建议的联邦学习中，将服务器模型参数作为查询对象，以客户模型参数作为键值，计算每个客户端的GRU神经网络各层相对于服务器GRU神经网络各层的注意力权值。可以通过客户端模型的细粒度聚合，对服务器模型进行微调以达到更好的泛化能力。</p>
<p><strong>联邦学习与无监督学习、半监督学习或迁移学习的结合</strong>是解决数据稀缺问题的一个很有市场的研究方向。</p>
<p>联邦学习中如何有效利用未标注数据。</p>
<h4 id="3-推荐系统"><a class="markdownIt-Anchor" href="#3-推荐系统"></a> 3. 推荐系统</h4>
<p>在推荐系统中，<strong>冷启动</strong>和用户数据隐私是两个未解决的主要问题。</p>
<p>一般来说，推荐模型可以分为四种：协同过滤、基于内容的推荐系统、基于模型的推荐系统和混合推荐系统。</p>
<ul>
<li>协同过滤（CF），通过对用户与商品的历史互动进行建模来实现推荐；矩阵高度系数，大多采用低秩因子分解方法/矩阵因子分解。</li>
<li>基于内容，商品由若干个关键词进行标记，而用户画像由描述该用户喜欢的商品种类的关键词组成，通过关键词对齐方法进行推荐；</li>
<li>基于模型，使用机器学习和深度学习技术，对用户-商品关系进行直接建模；适用于对非线性关系；</li>
<li>混合推荐，一种简单的混合方法是，先分别进行基于内容过滤预测和协同过滤预测，再将二者的结果聚合在一起。</li>
</ul>
<p>联邦协同过滤，或者使用深度因子分解机（Factorziation Machine，FM）模型替代协同过滤，进一步提高性能。</p>
<p>线上学习场景中应用联邦学习，即联邦在线学习排名（FederatedOnline Learning to Rank，FOLtR）。</p>
<p>一种针对推荐模型的联邦元学习框架，相比基线，联邦元学习推荐模型具有最高的预测精准度，并且仅需几个更新步骤便可以快速适应新用户。</p>
<h4 id="4-实际场景"><a class="markdownIt-Anchor" href="#4-实际场景"></a> 4. 实际场景</h4>
<p>金融、医疗、城市计算与智慧城市、边缘计算和物联网。</p>
<p>区块链具有不可变性和可跟踪性，是联邦学习中防止恶意攻击的有效工具。</p>
<p>随着探索更多的联邦学习应用场景，该领域变得越来越具有包容性。它涵盖了分布式机器学习、统计学、信息安全、加密算法、模型压缩、博弈论和经济学原理，以及激励机制设计等方面的研究和实践。</p>
<h1 id="联邦学习实战"><a class="markdownIt-Anchor" href="#联邦学习实战"></a> 《联邦学习实战》</h1>
<h2 id="一-背景"><a class="markdownIt-Anchor" href="#一-背景"></a> 一. 背景</h2>
<p>基于图的并行处理算法是DML最近一个比较新的方法。</p>
<h3 id="安全机制"><a class="markdownIt-Anchor" href="#安全机制"></a> 安全机制</h3>
<h4 id="1同态加密"><a class="markdownIt-Anchor" href="#1同态加密"></a> 1.同态加密</h4>
<p>可以分为三类：部分同态加密（Partially Homomorphic Encryp-tion，PHE），些许同态加密（Somewhat Homomorphic Encryption，SHE），全同态加密（Fully Homomorphic Encryption，FHE）。</p>
<h4 id="2差分隐私"><a class="markdownIt-Anchor" href="#2差分隐私"></a> 2.差分隐私</h4>
<p>采用了一种随机机制，使得当输入中的单个样本改变之后，输出的分布不会有太大的改变。</p>
<p>函数的输出结果对数据集里的任何特定记录都不敏感。因此，能被用于抵抗成员推理攻击。</p>
<p>可以分为中心化差分隐私和本地化差分隐私，区别主要在于差分隐私对数据处理的阶段不同。</p>
<p>目前实现差分隐私保护的主流方法是添加扰动噪声数据。定义全局敏感度。</p>
<p>拉普拉斯机制、高斯机制、指数机制</p>
<h4 id="3安全多方计算"><a class="markdownIt-Anchor" href="#3安全多方计算"></a> 3.安全多方计算</h4>
<p>MPC最初针对的是一个安全两方计算问题（即著名的“百万富翁问题”）而被正式提出的。</p>
<p>秘密共享（Secret Sharing，SS），不经意传输（ObliviousTransfer，OT），混淆电路（Garbled Circuit，GC）可以用来实现安全多方计算。</p>
<p>以上是联邦学习中涉及到的三大安全机制（最常用的还是同态加密），它们在计算性能、通信性能和安全性方面的对比如下：</p>
<ul>
<li>计算性能，耗时在求取梯度上，同态加密，计算在密文的状态下进行，密文的计算要比明文的计算耗时更长。</li>
<li>通信性能，同态加密传输的是密文数据，密文数据比明文数据占用的比特数要更大，因此传输效率要比明文慢；秘密共享为了保护数据隐私，通常会将数据进行拆分并向多方传输，完成相同功能的迭代。同态加密和差分隐私需要一次，而秘密共享需要多次数据传输才能完成。</li>
<li>安全性，同态加密由于传输的是密文数据，因此其安全性是最可靠的；秘密共享通过将模型参数数据进行拆分，只有当恶意客户端超过一定的数目并且相互串通合谋时，才有信息泄露的风险，总体上安全性较高；差分隐私对模型参数添加噪声数据，但添加的噪声会直接影响模型的性能。</li>
</ul>
<div align="center">
  <img src="/2021/07/01/fl/table.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<p>Python的常见安全计算库有pycrypto，Python-Paillier，differential-privacy，diffprivlib，MPyC等。</p>
<h2 id="二-python实现横向联邦"><a class="markdownIt-Anchor" href="#二-python实现横向联邦"></a> 二. Python实现横向联邦</h2>
<p>在本地以循环的方式来模拟，而没有涉及到网路通信模块开发。</p>
<p>一般训练时需要调整的参数有，训练的客户端数量、全局迭代次数、本地模型的迭代次数、本地训练相关的算法配置（学习率、优化算法、训练样本大小等）、模型信息、数据信息。</p>
<p>服务端类的主要函数包括：</p>
<ul>
<li>定义构造函数，第一，将配置信息拷贝到服务端中；第二，按照配置中的模型信息获取模型；</li>
<li>定义模型聚合函数</li>
<li>定义模型评估函数</li>
</ul>
<p>客户端主要函数是：</p>
<ul>
<li>定义构造函数</li>
<li>定义模型本地训练函数</li>
</ul>
<p>整体实现代码在配套的Github上，</p>
<h2 id="三-fate框架"><a class="markdownIt-Anchor" href="#三-fate框架"></a> 三. FATE框架</h2>
<p>FATE（Federated AI Technology Enabler），是微众银行AI部门发起的联邦学习开源项目，全球第一个联邦学习工业级开源框架，为联邦学习生态系统提供了可靠的安全计算框架。</p>
<p>FATE目前支持三种类型的单机安装，分别是：使用Docker镜像安装FATE；在主机中安装FATE；使用Docker从源代码中构建FATE。推荐使用Docker镜像安装FATE，这样可以大大降低产生问题的概率（注意docker及docker-compose版本以及请检查8080、9060和9080端口）。</p>
<p>为了降低开发人员的部署难度，VMware与微众银行联合开发了KubeFATE。</p>
<p>在金融领域的应用是信用风险管理、反洗钱应用和交通违章保险。</p>
<h3 id="1-横向逻辑回归"><a class="markdownIt-Anchor" href="#1-横向逻辑回归"></a> 1. 横向逻辑回归</h3>
<p>首先进行数据输入，将文件（如csv、txt等文本文件）转换为FATE支持的<strong>DTable格式</strong>。之后是模型训练，即数据转换为DTable格式后，FATE可以为模型训练构建流水线；最后是进行模型评估。</p>
<h1 id="相关文献"><a class="markdownIt-Anchor" href="#相关文献"></a> 相关文献</h1>
<p>杨强老师的联邦学习课程（2021年春）<a href="https://ising.cse.ust.hk/fl/index.html" target="_blank" rel="noopener">https://ising.cse.ust.hk/fl/index.html</a></p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86/">知识梳理</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/">联邦学习</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2021/07/05/leetcode/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">算法编程训练记录</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2021/06/29/dou-brother/">
                        <span class="hidden-mobile">兜哥学安全四件套笔记</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    function loadGitalk(){
      addScript('https://cdn.staticfile.org/gitalk/1.6.2/gitalk.min.js', function () {
        var gitalk = new Gitalk({
          clientID: '719893e76127bcc98b08',
          clientSecret: 'ed167d3d935e2922b47f190e1f36b026bd823a2d',
          repo: 'deepdeer.github.io',
          owner: 'DeepDeer',
          admin: 'DeepDeer',
          id: location.pathname,
          language: 'zh-CN',
          perPage: 15,
          pagerDirection: 'last',
          createIssueManually: 'false',
          distractionFreeMode: 'false'
        });
        gitalk.render('gitalk-container');
      });
    }
    createObserver(loadGitalk, 'gitalk-container');
  </script>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>




















</body>
</html>
