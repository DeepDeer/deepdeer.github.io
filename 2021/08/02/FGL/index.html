<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/deer-icon.png">
  <link rel="icon" type="image/png" href="/img/deer-icon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#87847e">
  <meta name="description" content="">
  <meta name="author" content="Skyla Sun">
  <meta name="keywords" content="">
  <title>联邦图模型研究工作梳理 - DeepDeer</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/gitalk/1.6.2/gitalk.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 40vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>日言寺青</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/fav.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
                联邦图模型研究工作梳理
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2021-08-02 16:01">
      2021年8月2日 下午
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      4.2k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      46
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <p>当前联邦学习方向风头正胜，GNN模型也在各种应用场景（如风控系统、欺诈检测、推荐系统、生物制药等）中取得良好表现。而由于隐私保护和商业竞争，GNN模型也受数据孤岛问题的限制。但目前只有少数工作和图模型的联邦学习（Federated Graph Learning，FGL）相关。也许是因为图模型训练过程中更加凸显了联邦学习中的技术缺陷，感觉这个方向有更多可研究的问题和挑战。</p>
<p>本文列举出当前现有的相关研究工作。</p>
<h2 id="基础概念"><a class="markdownIt-Anchor" href="#基础概念"></a> 基础概念</h2>
<h3 id="federated-graph-learning-a-position-paper-arxiv-2021"><a class="markdownIt-Anchor" href="#federated-graph-learning-a-position-paper-arxiv-2021"></a> 《Federated Graph Learning - A Position Paper》—— arxiv 2021</h3>
<p>本文对联邦图学习方法进行定义与分类。依据图数据在客户端上的分布情况，分为图间联邦、图内联邦、图结构联邦三类。其中，图内联邦又可以区分为横向联邦和纵向联邦。</p>
<p>基础定义沿用GCN [Kipf and Welling, 2016] 和 FedAvg [McMahan, 2017]中的概念。</p>
<h4 id="一-inter-graph-federated-learning"><a class="markdownIt-Anchor" href="#一-inter-graph-federated-learning"></a> 一. Inter-graph federated learning</h4>
<p>适用于图级别任务，客户端的每一个样本都是一个图。比如生物药性研究中，每个分子可以表示为由原子（节点）和化学键（边）组成的图模型。应用FedAvg时候全局模型为$$\hat{y_i}^{(k)} = H(X_i<sup>{(k)},A_i</sup>{(k)}, W)$$​，目标函数如下所示：</p>
<div align="center">
  <img src="/2021/08/02/FGL/inter.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<h4 id="二-intra-graph-federated-learning"><a class="markdownIt-Anchor" href="#二-intra-graph-federated-learning"></a> 二. Intra-graph federated learning</h4>
<p>每个客户端都拥有（潜在）整体大图的一部分。</p>
<h5 id="1-横向联邦"><a class="markdownIt-Anchor" href="#1-横向联邦"></a> 1. 横向联邦</h5>
<p>不同客户端的子图间有同样的属性和标签空间，但节点集合间由于缺少一些连接而隔离，<strong>也可以存在一些重复</strong>。一般支持图级别或链路级别的任务，如某社交APP中各用户设备保留其局部网络结构。应用FedAvg后全局模型为$$\hat{Y}^{(k)} = H(X<sup>{(k)},A</sup>{(k)}, W)$$​，优化目标为：</p>
<div align="center">
  <img src="/2021/08/02/FGL/hintra.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<h5 id="2-纵向联邦"><a class="markdownIt-Anchor" href="#2-纵向联邦"></a> 2. 纵向联邦</h5>
<p>不同客户端在节点空间上是重合的，但拥有不同的属性和标签（该场景支持多任务学习）。此种联邦的目的在于组合不同客户端的节点属性并共享各方面的标签。常见于多机构间合作，如图所示，比如文章《Towards federated graph learning for collaborative ﬁnancial crimes detection》和《Fede: Embedding knowledge graphs in federated setting》。</p>
<div align="center">
  <img src="/2021/08/02/FGL/vintra.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<h4 id="三-graph-structured-federated-learning"><a class="markdownIt-Anchor" href="#三-graph-structured-federated-learning"></a> 三. Graph-structured federated learning</h4>
<p>除了数据呈图结构外，图结构还可能呈现在参加联邦的客户端中。此类联邦中，服务器端使用GNN模型来聚合来自不同客户端的本地模型信息。本质上算是一种特殊的联邦学习模型聚合方式。最经典的应用是基于不同地理位置监控设备的数据进行交通流量预测，使用GNN处理设备间的空间信息《Cross-node federated graph neural network for spatio-temporal data modeling》。</p>
<p>三种类型图联邦方法特点总结如下：</p>
<div align="center">
  <img src="/2021/08/02/FGL/sum.jpg" srcset="/img/loading.gif" width="60%" height="60%" alt="oauth">
</div>
<h4 id="一些挑战"><a class="markdownIt-Anchor" href="#一些挑战"></a> 一些挑战</h4>
<h5 id="1-non-iid-graph-structure"><a class="markdownIt-Anchor" href="#1-non-iid-graph-structure"></a> 1. Non-IID graph structure</h5>
<p>任何一种联邦图模型学习方法都避免不了数据非独立同分布问题，这个问题严重影响着联邦模型的收敛速度和准确性。</p>
<p>而相对于传统数据，图数据中除了属性和标签分布外，还有边（即结构信息）带来的影响。</p>
<p>研究工作《Asfgnn: Automated separated-federated graph neural network》和《Graphﬂ: A federated learning framework for semi-supervised node classiﬁcation on graphs》尝试改善这一问题，但目前还没有可以完全解决的方法。</p>
<p>图结构信息特性包括如：度分布、平均路径长度、平均聚类系数等。<strong>研究一下这些特性</strong>也许有助于解决non-IID问题。</p>
<p>另外，也许可以采纳传统FL中一些个性化模型学习的思路，如FedNAS（Fednas: Federated deep learning via neural architecture search）等。</p>
<h5 id="2-横向图内联邦的孤岛问题"><a class="markdownIt-Anchor" href="#2-横向图内联邦的孤岛问题"></a> 2. 横向图内联邦的孤岛问题</h5>
<p>通常图表示学习方法依赖于在多跳邻居间进行游走和信息聚合，但现在这个大图被分割在不同客户间，而用户本地数据无法支持多跳信息聚合。</p>
<p>也许可以通过本地<strong>子图间潜在边发现</strong>来解决这个问题。研究工作《Fedgnn: Federated graph neural network for privacy-preserving recommendation》中也有提及这一点，并提出了一种基于同态加密的子图扩充方法。</p>
<h5 id="3-纵向图内联邦的实体匹配和安全数据共享"><a class="markdownIt-Anchor" href="#3-纵向图内联邦的实体匹配和安全数据共享"></a> 3. 纵向图内联邦的实体匹配和安全数据共享</h5>
<p>VFL需要做到同时保证准确性、隐私性和通信效率，但目前这方面的研究工作很少。</p>
<p>《Fede: Embedding knowledge graphs in federated setting》尝试基于一个由服务器维护的匹配表完成聚合，但这在一定程度上违背了隐私保护的目的。</p>
<p>在传统VFL领域，《Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption》使用同态加密方法联邦训练逻辑斯特回归模型，而《Multiparticipant multi-class vertical federated learning》将其推广到多参与者与多分类任务。</p>
<h5 id="4-图内联邦数据集问题"><a class="markdownIt-Anchor" href="#4-图内联邦数据集问题"></a> 4. 图内联邦数据集问题</h5>
<p>目前做实验基本是通过模拟方法随机拆分数据，而没有比较贴近现实的数据集。</p>
<h5 id="5-通信及内存消耗"><a class="markdownIt-Anchor" href="#5-通信及内存消耗"></a> 5. 通信及内存消耗</h5>
<p>联邦学习中一般局部模型会放到端侧，这对其计算能力有较高要求，而端侧与服务器间的通信也带来了额外的带宽消耗。</p>
<p>也许针对GNN模型的压缩技术（包括模型量化、剪枝、蒸馏等）可以缓解这一问题。</p>
<p>《Degree-quant: Quantization-aware training for graph neural networks》涉及GNN的模型量化方法。《Distilling knowledge from graph convolutional networks》是GNN蒸馏方法。《Lightrec: A memory and search-efﬁcient recommender system》提出模型量化方法。</p>
<h5 id="6-联邦学习安全性问题"><a class="markdownIt-Anchor" href="#6-联邦学习安全性问题"></a> 6. 联邦学习安全性问题</h5>
<p>这个部分可以再专门写一篇文章，目前人智领域以及网络安全领域顶会上都有很多相关工作。</p>
<h3 id="fedgraphnna-federated-learning-system-and-benchmark-for-graph-neural-networks"><a class="markdownIt-Anchor" href="#fedgraphnna-federated-learning-system-and-benchmark-for-graph-neural-networks"></a> 《FedGraphNN：A Federated Learning System and Benchmark for Graph Neural Networks》</h3>
<p>文章没有相关算法创新，偏重于工程（<a href="https://github.com/FedML-AI/FedGraphNN%EF%BC%89%EF%BC%8C%E6%98%AF%E5%9F%BA%E4%BA%8EFedML%E6%A1%86%E6%9E%B6%E7%9A%84%E9%92%88%E5%AF%B9GNN%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0%EF%BC%8C%E9%92%88%E5%AF%B9Graph-level" target="_blank" rel="noopener">https://github.com/FedML-AI/FedGraphNN），是基于FedML框架的针对GNN算法的实现，针对Graph-level</a> FL，即每个客户端有自己的图模型。同时提供了一个生物分子数据集hERG。这项工作<strong>主打graph-level任务</strong>，用到的数据集基本都是生物基因、化学分子数据集。</p>
<p>其中的模型阐述部分（Formulation）值得写作参考，实验中列出的超参可以参考。</p>
<p>实验部分采用LDA（latent dirichlet allocation）方法划分不均衡的数据集。</p>
<p>实验结果表明：</p>
<ul>
<li>小型数据集上，FGL可以达到和集中式学习相媲美的效果；但大数据的non-IID特性更为明显，FGL效果有所下降；</li>
<li>直接将现有方法应用于GNN无法达到良好效果，基本相对于集中式学习都有所折扣ROC-AUC下降大概0.05~0.1。</li>
<li>可能由于non-IID影响，集中式表现更好的模型在联邦模式中不一定表现最好，比如文中实验里GAT效果下降明显</li>
<li>底端通信采用RPC（如果设备只能依靠公网IP找打的话需要使用）或者MPI效率都差不多；</li>
</ul>
<p>主要是看看里面的代码实现。有关代码的学习实践笔记见。</p>
<h2 id="面向non-iid问题"><a class="markdownIt-Anchor" href="#面向non-iid问题"></a> 面向non-IID问题</h2>
<h3 id="fedglfederated-graph-learning-framework-with-global-self-supervision"><a class="markdownIt-Anchor" href="#fedglfederated-graph-learning-framework-with-global-self-supervision"></a> 《FedGL：Federated Graph Learning Framework with Global Self-Supervision》</h3>
<p>定义了<strong>在图数据上</strong>进行联邦学习会面临的两大问题：<strong>heterogeneity和complementarity</strong>。如下图所示，<strong>异构性</strong>即每个客户端的图数据上节点数、边数和标签情况分布不同；<strong>互补性</strong>即每个客户端上的节点以及边的情况可能有重合/补充，比如client A这里节点5和节点7之间没有边，但client B这边是有边的。</p>
<div align="center">
  <img src="/2021/08/02/FGL/ques.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<p>针对这两个问题，作者在传统FL步骤基础上加入了对于<strong>client端预测结果和节点表征结果</strong>传送和处理的步骤，在server端形成<strong>全局伪标签（non-IID问题）<strong>和</strong>全局伪图（互补性问题）</strong>。</p>
<div align="center">
  <img src="/2021/08/02/FGL/fedgl.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<h4 id="1-全局伪标签"><a class="markdownIt-Anchor" href="#1-全局伪标签"></a> 1. 全局伪标签</h4>
<p>处理各client端的预测结果，加权组合形成全部节点的预测结果<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>P</mi><mn>1</mn></msub><mi mathvariant="normal">，</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>P</mi><mi>K</mi></msub></mrow><annotation encoding="application/x-tex">P_1，...,P_K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">，</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>​。在每个预测结果中选取信度较高的样本的标签作为标签。</p>
<p>Server端将这些伪标签数据下放，提升client端模型训练效果。</p>
<h4 id="2全局伪图"><a class="markdownIt-Anchor" href="#2全局伪图"></a> 2.全局伪图</h4>
<p>处理各client端的节点表征结果，加权组合形成全局节点表征<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>H</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>H</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">H_1,...,H_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, 即矩阵<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>H</mi><mo>˙</mo></mover></mrow><annotation encoding="application/x-tex">\dot H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9201900000000001em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201900000000001em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.08333000000000002em;">˙</span></span></span></span></span></span></span></span></span>, 将此矩阵乘以其转置得到整个图的伪邻接矩阵，下放至client端提升模型效果。</p>
<p>client接收到server端的信息由三种：模型信息、伪标签信息和伪全图信息。伪全图信息被直接用来完善当前client上的图结构（补全边但是不增加节点），伪标签则被用来构建自监督学习（在损失函数中加入<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mrow><mi>S</mi><mi>S</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{SSL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>项）。</p>
<p><strong>【问题就在于，这些也把client端的信息暴露的差不多了啊…】</strong></p>
<p>以上操作需要server知道每个client上到底有哪些节点且每个节点有单独索引的基础上，这样才能处理client上传的预测值和表征向量。这样联邦学习只保护了节点的属性、图结构信息以及本身的标签，但是暴露了节点信息（可能某些情况下不重要？）</p>
<p>实验安排、考虑到的各个方面以及描述方法值得借鉴。</p>
<h3 id="fedgnnfederated-graph-neural-network-for-privacy-preserving-recommendationkdd-2021"><a class="markdownIt-Anchor" href="#fedgnnfederated-graph-neural-network-for-privacy-preserving-recommendationkdd-2021"></a> 《FedGNN：Federated Graph Neural Network for Privacy-Preserving Recommendation》KDD 2021</h3>
<p>传统的基于GNN的推荐系统依赖于集中式的数据存储，但实际中用户数据极具私密性。但如果简单地使用分布式学习技术会有如下问题：</p>
<ul>
<li>本地数据量过小，不支持训练GNN模型；</li>
<li>当与全局模型同步时，本地GNN模型会泄露本地数据；</li>
<li>本地数据只包含user-item的一阶交互信息，没有办法处理高阶信息</li>
</ul>
<p>文章提出一种基于联邦学习方法FedGNN的<strong>推荐系统</strong>，而且重点针对训练过程中的隐私性提出了几点创新方法。</p>
<p>但这个系统的实现前提是：当前user节点与其交互的item节点相连，同时还与其邻居节点相连。这就<strong>要求用户知道自己的邻居是谁</strong>。过程中使用同态加密手段处理，保证中心服务器可以依据item完成user节点匹配但同时无法知道每个user到底查了什么item。</p>
<blockquote>
<p>The local subgraph on each user clients is constructed from the user-item interaction data and the nieghboring users that have interacted items with this user.</p>
</blockquote>
<div align="center">
  <img src="/2021/08/02/FGL/fedgnn.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<p>在模型的联邦计算方面没有太多创新，但关注了联邦中参数传递过程中的隐私泄露问题。通过构造伪交互item和本地差分隐私方法分别保护embedding层和GNN模型的梯度信息。</p>
<p>文章思路很灵巧，对比的Baseline包括集中式的协同过滤、矩阵分解和GNN方法（该方法相比它们安全性更高），以及联邦的协同过滤和矩阵分解方法（该方法相比它们的推荐效果要好，但感觉这主要是GNN的功劳，而文章的主要贡献就是使FedGNN变得可实现，虽然我觉得这个通过上传item同态加密结果，查找邻居的方法不太实际）。</p>
<h3 id="subgraph-federated-learning-with-missing-neighbor-generation"><a class="markdownIt-Anchor" href="#subgraph-federated-learning-with-missing-neighbor-generation"></a> 《Subgraph Federated Learning with Missing Neighbor Generation》</h3>
<p>直接使用FedAvg训练一个图模型（GraphSAGE）命名为FedSage，在此基础上提出一个链路生成器形成FedSage+模型。</p>
<p>假设不同客户端中没有重复的节点数据，而面临一个问题即，<strong>跨子图的边不会被任何一个客户端捕捉到</strong>。</p>
<p>通过设计一个遗失邻居节点生成器NeighGen来完成子图补全，如下图所示，包括编码器和生成器两个部分。编码器是一个GNN模型，以待修复图为输入，输出计算后的节点表征向量。生成器包括节点数量预测器dGen和特征生成器fGen，二者都是全连接网络模型。模型均由现有数据隐藏部分数据后训练而得。</p>
<div align="center">
  <img src="/2021/08/02/FGL/generate.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<p>通过组合损失函数（加权），将每个客户端本地的NeighGen以及其本地节点分类器GraphSAGE共同训练。</p>
<p>但这样的训练框架下，每个客户端的NeighGen依然是仅仅基于本地数据，会存在偏差，所以还要设计其联邦学习方法。然而，直接将FedAvg应用到上述损失函数上会有负面效果。因为原本不同客户端就应当生成不同的“遗失邻居”。因此我们将fGen的损失函数由公式5转为公式6的部分，代表希望生成的邻居节点与其它客户端中遗失的节点类似。（这…，我为啥有点…，而且<strong>你是怎么知道其它客户端中隐藏的节点信息的呢？？？？</strong>）</p>
<div align="center">
  <img src="/2021/08/02/FGL/e5.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<div align="center">
  <img src="/2021/08/02/FGL/e6.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<h3 id="federated-graph-classification-over-non-iid-graphs"><a class="markdownIt-Anchor" href="#federated-graph-classification-over-non-iid-graphs"></a> 《Federated Graph Classification over Non-IID Graphs》</h3>
<p>从题目可以看出，这篇文章<strong>也是主打图级别</strong>任务。（作者竟然说对于节点分类/链路预测任务的研究工作已经有很多了…）</p>
<p>首先观察不同领域的图数据间是否存在一些共享特性（比如节点度分布、最短路径长度、最大组成大小、聚类系数等）。经过和相同节点和边数量随机生成的模型相比发现确实如此。但与此同时不同客户端间的图数据也在结构和特征信息上存在non-IID特性。</p>
<p>这篇文章分析了同一数据集、同一领域数据、跨领域数据三种不同层次中存在的异构性造成的影响。</p>
<p>考虑使用基于聚类的联邦学习框架，根据梯度信息，将较为相似的客户端聚为一类，而为不同的簇维护不同的全局模型。而且这个聚类的方式是动态的。</p>
<p>另外作者发现在每轮迭代中，梯度范数波动很大，而且不同客户端的梯度范数的范围很不同。如果基于这样的信息聚类，结果会不准确。为了解决这种问题提出进阶版本模型GCFL+，此方法<strong>不仅基于当前梯度信息聚类</strong>，而是维护一个$$d$$长度的梯度窗口。</p>
<h3 id="vertically-federated-graph-neural-network-for-privacy-preserving-node-classification"><a class="markdownIt-Anchor" href="#vertically-federated-graph-neural-network-for-privacy-preserving-node-classification"></a> 《Vertically federated graph neural network for privacy-preserving node classification》</h3>
<p>蚂蚁金服团队与浙大、北大合作的作品。</p>
<h3 id="asfgnn-automated-separated-federated-graph-neural-network"><a class="markdownIt-Anchor" href="#asfgnn-automated-separated-federated-graph-neural-network"></a> 《Asfgnn: Automated separated-federated graph neural network》</h3>
<p>支持自动化超参优化。</p>
<h3 id="fl-agcns-federated-learning-framework-for-automatic-graph-convolutional-network-search"><a class="markdownIt-Anchor" href="#fl-agcns-federated-learning-framework-for-automatic-graph-convolutional-network-search"></a> 《FL-AGCNS: Federated learning framework for automatic graph convolutional network search》</h3>
<h3 id="spreadgnnserverless-multi-task-federated-learning-for-graph-neural-networks"><a class="markdownIt-Anchor" href="#spreadgnnserverless-multi-task-federated-learning-for-graph-neural-networks"></a> 《SpreadGNN：Serverless Multi-task Federated Learning for Graph Neural Networks》</h3>
<p>从题目可以看出，这篇文章主打<strong>无服务器</strong>联邦，而且每个用户可能拥有其样本数据中的部分标签。该方法可以处理不同客户端间数据集大小和标签分布的non-IID问题。而且即便在用户只能和部分邻居通信时也可以保持比较好的检测效果。</p>
<p>文章重点强调了联邦多任务学习（Federated Multitask Learning, FMTL），在损失函数中包括了任务之间的关系。</p>
<p>而处理“没有一个中央服务器”的挑战：</p>
<h3 id="graphfl-a-federated-learning-framework-for-semi-supervised-node-classification-on-graphs"><a class="markdownIt-Anchor" href="#graphfl-a-federated-learning-framework-for-semi-supervised-node-classification-on-graphs"></a> 《Graphﬂ: A federated learning framework for semi-supervised node classiﬁcation on graphs》</h3>
<p>现有联邦学习方法存在以下问题：1）在Non-IID数据下表现不好；2）无法处理带有新标签的数据；3）无法使用未标记数据。而这些问题在图数据上会表现得非常明显。</p>
<p>本文使用元学习方法（使用MAML）解决前两个问题，并利用自训练（self-training）技术利用未标记的图数据。</p>
<p>作者不再致力于得到一个在所有数据集上都表现特别好的模型，而是将不同客户端的局部模型训练视为元学习中的一个任务，使用MAML学习到task-independent初始化参数。</p>
<h3 id="federated-dynamic-gnn-with-secure-aggregation"><a class="markdownIt-Anchor" href="#federated-dynamic-gnn-with-secure-aggregation"></a> 《Federated dynamic gnn with secure aggregation》</h3>
<p>在多用户图序列数据中，学习目标的动态表征。</p>
<h3 id="distributed-graph-convolutional-networks"><a class="markdownIt-Anchor" href="#distributed-graph-convolutional-networks"></a> 《Distributed graph convolutional networks》</h3>
<p>分布式GNN训练方法，保留了子图间的边连接。</p>
<h3 id="fede-embedding-knowledge-graphs-in-federated-setting"><a class="markdownIt-Anchor" href="#fede-embedding-knowledge-graphs-in-federated-setting"></a> 《Fede: Embedding knowledge graphs in federated setting》</h3>
<h3 id="towards-federated-graph-learning-for-collaborative-financial-crimes-detection"><a class="markdownIt-Anchor" href="#towards-federated-graph-learning-for-collaborative-financial-crimes-detection"></a> 《Towards federated graph learning for collaborative ﬁnancial crimes detection》</h3>
<h3 id="cross-node-federated-graph-neural-network-for-spatio-temporal-data-modeling"><a class="markdownIt-Anchor" href="#cross-node-federated-graph-neural-network-for-spatio-temporal-data-modeling"></a> 《Cross-node federated graph neural network for spatio-temporal data modeling》</h3>
<h3 id="sgnn-a-graph-neural-network-based-federated-learning-approach-by-hiding-structure"><a class="markdownIt-Anchor" href="#sgnn-a-graph-neural-network-based-federated-learning-approach-by-hiding-structure"></a> 《Sgnn: A graph neural network based federated learning approach by hiding structure》</h3>
<h3 id="locally-private-graph-neural-networks"><a class="markdownIt-Anchor" href="#locally-private-graph-neural-networks"></a> 《Locally private graph neural networks》</h3>
<h3 id="peer-to-peer-federated-learning-on-graphs"><a class="markdownIt-Anchor" href="#peer-to-peer-federated-learning-on-graphs"></a> 《Peer-to-peer federated learning on graphs》</h3>
<h3 id="cluster-driven-graph-federated-learning-over-multiple-domains"><a class="markdownIt-Anchor" href="#cluster-driven-graph-federated-learning-over-multiple-domains"></a> 《Cluster-driven graph federated learning over multiple domains》</h3>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86/">知识梳理</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E5%9B%BE%E6%A8%A1%E5%9E%8B/">图模型</a>
                    
                      <a class="hover-with-bg" href="/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/">联邦学习</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2021/08/13/cs-base/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">一些计算机基础知识读书笔记</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2021/07/14/weird/">
                        <span class="hidden-mobile">杜克大学《怪诞行为学》</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    function loadGitalk(){
      addScript('https://cdn.staticfile.org/gitalk/1.6.2/gitalk.min.js', function () {
        var gitalk = new Gitalk({
          clientID: '719893e76127bcc98b08',
          clientSecret: 'ed167d3d935e2922b47f190e1f36b026bd823a2d',
          repo: 'deepdeer.github.io',
          owner: 'DeepDeer',
          admin: 'DeepDeer',
          id: location.pathname,
          language: 'zh-CN',
          perPage: 15,
          pagerDirection: 'last',
          createIssueManually: 'false',
          distractionFreeMode: 'false'
        });
        gitalk.render('gitalk-container');
      });
    }
    createObserver(loadGitalk, 'gitalk-container');
  </script>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- KaTeX -->
    <link  rel="stylesheet" href="https://cdn.staticfile.org/KaTeX/0.11.1/katex.min.css" />
  
















</body>
</html>
