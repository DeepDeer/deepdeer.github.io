<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/deer-icon.png">
  <link rel="icon" type="image/png" href="/img/deer-icon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#87847e">
  <meta name="description" content="">
  <meta name="author" content="Skyla Sun">
  <meta name="keywords" content="">
  <title>兜哥学安全四件套笔记 - DeepDeer</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/gitalk/1.6.2/gitalk.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 40vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>深鹿计划</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/fav.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
                兜哥学安全四件套笔记
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2021-06-29 09:51">
      2021年6月29日 上午
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      19.6k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      216
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <p>为了整理AI in Cybersecurity的应用及研究场景，粗浅浏览一些这一系列书目，包括《Web安全之机器学习入门》、《Web安全之深度学习入门》、《Web安全之强化学习与GAN》、《AI安全之对抗样本入门》。在微信读书里都可以在线免费阅读。这几本书都比较粗浅，可以选择感兴趣的领域深入研究下。</p>
<p>最近十分痛苦地认识到如果当年认真研究手头资料，会有更加不错的科研结果，也无需度过大概5年多的黑暗时光。但一切都是最好的安排，活在当下，面向未来。</p>
<h1 id="web安全之机器学习入门"><a class="markdownIt-Anchor" href="#web安全之机器学习入门"></a> 《Web安全之机器学习入门》</h1>
<h2 id="一-环境基础"><a class="markdownIt-Anchor" href="#一-环境基础"></a> 一. 环境基础</h2>
<p>Python重点库：Numpy、Scipy、NTLK（NLP领域）、Scikit-learn等、Tensorflow（现在学术上基本都使用pytorch，也写了相关笔记）。</p>
<pre><code class="hljs python"><span class="hljs-comment">## NTLK 重点功能</span>
<span class="hljs-keyword">import</span> ntlk
<span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> treebank
sentence = <span class="hljs-string">'At eight on Thursday morning'</span>
tokens = nltk.word_tokenize(sentence)
tagged = nltk.pos_tag(tokens)
entities = nltk.chunk.ne_chunk(tagged) <span class="hljs-comment"># 语法树</span>
t = treebank.parsed_sents(<span class="hljs-string">'wsj_0001.mrg'</span>)[<span class="hljs-number">0</span>]
t.draw()</code></pre>
<p>数据集：</p>
<ul>
<li>KDD99（DAPRA，美国国防部高级研究计划局），9周网络连接与系统审计数据。异常类型被细分为4大类共39种攻击类型，其中22种攻击类型出现在训练集中，另有17种未知攻击类型出现在测试集中。网络入侵检测领域的权威测试集。前41想特征可以分为4大类：TCP连接基本特征、TCP连接的内容特征、基于时间的网络流量统计特征、基于主机的网络流量统计特征等。</li>
<li>HTTP DATASET CSIC 2020，针对Web服务的正常请求和25，000个攻击请求，包括SQL注入、缓冲区溢出、信息泄露、文件包含、xss等，广泛应用于WAF类产品测评。</li>
<li>SEA包含70多个UNIX系统用户行为日志，命令序列表示，100个命令为一块，共150个块，前三分之一数据块用作训练该用户正常行为模型，剩余三分之二数据块随机插入了测试用的恶意数据。将连续数据块看作一个会话，只能模拟连续会话关联的攻击行为；由于缺乏用户详细个人信息（职位、权限等）、数据维度单一（仅有命令信息）以及构造性（恶意数据由人工模拟）等因素，数据集在内部威胁检测研究中作用有限。</li>
<li>Schonlau（<a href="http://www.schonlau.net/%EF%BC%89%E5%8F%91%E5%B8%83%E9%92%88%E5%AF%B9Linux%E6%93%8D%E4%BD%9C%E7%9A%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%EF%BC%8C50%E4%B8%AA%E7%94%A8%E6%88%B7%E7%9A%84%E6%93%8D%E4%BD%9C%E6%97%A5%E5%BF%97%EF%BC%8C%E6%AF%8F%E4%B8%AA%E6%97%A5%E5%BF%97%E5%8C%85%E5%90%AB15000%E6%9D%A1%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%EF%BC%8C%E5%85%B6%E4%B8%AD%E5%89%8D5000%E6%9D%A1%E9%83%BD%E6%98%AF%E6%AD%A3%E5%B8%B8%E6%93%8D%E4%BD%9C%EF%BC%8C%E5%90%8E%E9%9D%A2%E7%9A%8410000%E6%9D%A1%E6%97%A5%E5%BF%97%E4%B8%AD%E9%9A%8F%E6%9C%BA%E5%8C%85%E5%90%AB%E6%9C%89%E5%BC%82%E5%B8%B8%E6%93%8D%E4%BD%9C%E3%80%82%E6%AF%8F100%E6%9D%A1%E6%93%8D%E4%BD%9C%E4%BD%9C%E4%B8%BA%E4%B8%80%E4%B8%AA%E6%93%8D%E4%BD%9C%E5%BA%8F%E5%88%97%EF%BC%8C%E5%90%8C%E6%97%B6%E8%BF%9B%E8%A1%8C%E6%A0%87%E6%B3%A8%EF%BC%8C%E6%AF%8F%E4%B8%AA%E6%93%8D%E4%BD%9C%E5%BA%8F%E5%88%97%E5%8F%AA%E8%A6%81%E6%9C%891%E6%9D%A1%E6%93%8D%E4%BD%9C%E5%BC%82%E5%B8%B8%E5%B0%B1%E8%AE%A4%E4%B8%BA%E8%BF%99%E4%B8%AA%E6%93%8D%E4%BD%9C%E5%BA%8F%E5%88%97%E5%BC%82%E5%B8%B8%E3%80%82" target="_blank" rel="noopener">http://www.schonlau.net/）发布针对Linux操作的训练数据，50个用户的操作日志，每个日志包含15000条操作命令，其中前5000条都是正常操作，后面的10000条日志中随机包含有异常操作。每100条操作作为一个操作序列，同时进行标注，每个操作序列只要有1条操作异常就认为这个操作序列异常。</a></li>
<li>ADFA-LD主机级入侵检测数据集，包括Linux和Windows系统，记录了系统调用数据，已完成特征化和标注。每个数据文件都独立记录了一段时间内的系统调用顺序，每个系统调用都用数字编号。</li>
<li>Alexa域名数据集，Alexa是当前拥有URL数量最庞大、排名信息发布最详尽的网站。Alexa排名是常被引用的用来评价某一网站访问量的指标之一。</li>
<li>少量多种安全相关数据，开源攻击数据网站http://www.secrepo.com/</li>
<li>Movie Review Data，包含1000条正面的评论和1000条负面评论，被广泛应用于文本分类，尤其是恶意评论识别方面。记录的都是原始评论数据，全部为英文。</li>
<li>SpamBase入门级垃圾邮件分类数据集，不是原始的邮件内容而是已经特征化的数据，58个特征。</li>
<li>Enron数据集，真实邮件，归档邮件来研究文档分类、词性标注、垃圾邮件识别等，广义的Enron数据集指全量真实且未被标记的Enron公司归档邮件。</li>
</ul>
<h2 id="二-处理技巧"><a class="markdownIt-Anchor" href="#二-处理技巧"></a> 二. 处理技巧</h2>
<h3 id="1-特征提取"><a class="markdownIt-Anchor" href="#1-特征提取"></a> 1. 特征提取</h3>
<p>数字型特征预处理包括标准化、归一化和正则化。</p>
<pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing
X_scaled = preprocessing.scale(X)
X_normalizzed = preprocessing.normalize(X, norm=<span class="hljs-string">'l2'</span>)

min_max_scalar = preprocessing.MinMaxScalar()
X_minmax = min_max_scalar.fit_transform(X_train)</code></pre>
<p>文本特征切分后可以直接词典化，或选用词集/词袋（加入频率统计）模型。</p>
<pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_extraction <span class="hljs-keyword">import</span> DictVectorizer
<span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer
<span class="hljs-comment"># 特征取值词典化，比如city：&#123;'Beijing','London','Shanghai','Sichuan'&#125;</span>
vec = DictVectorizer()
vec.fit_transform(X).toarray()
vec.get_feature_names()
<span class="hljs-comment"># 词袋模型</span>
vectorizer = CountVectorizer(min_df=<span class="hljs-number">1</span>)
X = vectorizer.fit_transform(corpus).toarray()
vectorizer.get_feature_names()
vocabulary = vectorizer.vocabulary_
new_vectorizer = CounterVectorizer(min_df=<span class="hljs-number">1</span>, vocabulary=vocabulary)</code></pre>
<h2 id="三-web安全场景"><a class="markdownIt-Anchor" href="#三-web安全场景"></a> 三. Web安全场景</h2>
<h3 id="1-xss攻击"><a class="markdownIt-Anchor" href="#1-xss攻击"></a> 1. XSS攻击</h3>
<p>Cross Site Scripting，跨站脚本攻击，允许恶意Web用户将代码植入到提供给其他用户使用的页面中。这种类型的漏洞由于被黑客用来编写危害性更大的网络钓鱼攻击而变得广为人知。黑客界共识是：跨站脚本攻击是新型的“缓冲区溢出攻击”，而JavaScript是新型的“ShellCode”。</p>
<p>XSS的攻击方式就是想办法“教唆”用户的浏览器去执行一些这个网页中原本不存在的前端代码。</p>
<p>XSS被用来，盗取各类用户账号（机器登录账号、用户网银账号、各类管理员账号），控制企业数据（读取、篡改、添加、删除企业敏感数据），非法转账，强制发送电子邮件，网站挂马，控制受害者机器向其他网站发起攻击。</p>
<p>XSS分为反射型XSS、存储型XSS、DOM型XSS。</p>
<p>反射型XSS，非持久性XSS，是现在最常见的一种XSS漏洞。Payload一般写在URL中，之后设法让被害者点击这个链接。</p>
<p>存储型XSS，持久型XSS，存储型XSS是最危险的一种跨站脚本。被服务器端接收并存储，当用户访问该网页时，这段XSS代码被读出来响应给浏览器。不需要依靠用户手动触发。</p>
<p>DOM型XSS，Document Object Model，即文档对象模型。不需要与服务器交互的，它只发生在客户端处理数据阶段。DOM型XSS是前端代码中存在了漏洞，而反射型XSS是后端代码中存在了漏洞。</p>
<p>当前存在多种XSS攻击形式，如IMG标签无分好无引号、大小写不敏感、URL编码、IP十进制、绕符号过滤等。</p>
<p>目前已出现利用JS特性进行特殊编码变形绕过防御的手段，如Jsfuck（针对常见的JS函数、语法进行编码转换）、Aaencode（把js转为文字表情符号）等。还有大量XSS平台，自动生成js攻击载荷，常见做法是通过钓鱼邮件，IM消息诱骗受害者点击。</p>
<p><strong>应用案例1</strong>，2016年雅虎邮箱XSS漏洞，首先一封带有已知HTML标签的邮件进行fuzz，发现雅虎自动过滤bool属性的值但会保留等号，黑客可以无限制地插入带bool属性的HTML标签。</p>
<p><strong>应用案例2</strong>，WordPress插件Jetpack存储型XSS漏洞。</p>
<h3 id="2-sql注入"><a class="markdownIt-Anchor" href="#2-sql注入"></a> 2. SQL注入</h3>
<p>通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。利用现有应用程序，将SQL命令注入到后台数据库引擎执行。</p>
<p>常见SQL注入方式有强制产生错误（准备步骤），非主流通道技术（E-mail、DNS以及数据库连接），使用特殊字符，使用条件语句，利用存储过程，避开输入过滤技术，推断技术。</p>
<p>常见工具包括sqlmap（免费开源），HAVIJ等。</p>
<h3 id="3-webshell"><a class="markdownIt-Anchor" href="#3-webshell"></a> 3. Webshell</h3>
<p>以ASP、PHP、JSP或者CGI等网页文件形式存在的一种命令执行环境，也可以将其称为一种网页后门。</p>
<p>黑客在入侵了一个网站后，通常会将ASP或PHP后门文件与网站服务器Web目录下正常的网页文件混在一起，然后就可以使用浏览器来访问ASP或者PHP后门，得到一个命令执行环境，从而达到控制网站服务器的目的。</p>
<p>在KILLCHAIN模型中，WebShell属于command&amp;control环节。</p>
<p>Webshell通常具有以下功能：环境探针、资源管理、文件编辑、执行OS命令、读取注册表、创建Socket、调用系统组件。</p>
<h3 id="4-僵尸网络"><a class="markdownIt-Anchor" href="#4-僵尸网络"></a> 4. 僵尸网络</h3>
<p>僵尸网络是互联网上受到黑客集中控制的一群计算机，往往被黑客用来发起大规模的网络攻击，如分布式拒绝服务攻击（DDoS）、海量垃圾邮件等，同时黑客控制的这些计算机所保存的信息，进行资源滥用或挖矿。</p>
<p>Mirai僵尸网络（10万计的物联网设备）2016年对美国域名解析服务提供商Dyn公司进行峰值达1.1Tbps的DDoS攻击。Mirai恶意程序通过扫描物联网设备，尝试默认通用密码进行登录操作，一旦成功即将这台物联网设备作为“肉鸡”纳入僵尸网络中，进而操控其攻击其他网络设备。</p>
<p>2017年，Radware研究人员发现了Brickerbot僵尸网络，和Mirai僵尸网络有诸多相似之处，区别在于它可以对配置不当的物联网设备造成永久性破坏。通过部署针对性蜜罐而被发现。Brickerbot僵尸网络通过Telnet暴力攻击物联网设备。大部分被僵尸网络攻击的设备被Shodan识别为Ubiquiti。Bricker不下载二进制文件，很难分析。恶意代码首先获得对设备的访问，然后通过rm -rf /*命令擦除设备内存，禁用TCP时间戳，并将内核线程的最大数量限制为一个。刷新所有iptables防火墙和NAT规则（见图4-22），并添加一条规则来删除所有传出的数据包。</p>
<p>2016年第4季度IMPERVA缓解的最大型DDoS攻击，规模为650Gbps，依托Leet僵尸网络发起。</p>
<p>Amnesia僵尸网络利用了未修补的远程代码执行漏洞，目标是嵌入式系统。</p>
<h2 id="四-机器学习算法及应用场景"><a class="markdownIt-Anchor" href="#四-机器学习算法及应用场景"></a> 四. 机器学习算法及应用场景</h2>
<h3 id="1-k近邻"><a class="markdownIt-Anchor" href="#1-k近邻"></a> 1. K近邻</h3>
<p>KNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别，因此较适合类域交叉或重叠较多的待分样本集。</p>
<p>K值含义 - 对于一个样本X，要给它分类，首先从数据集中，在X附近找离它最近的K个数据点，将它划分为归属于类别最多的一类。</p>
<p>常用算法包括Brute Force、K-D Tree和Ball Tree。</p>
<pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> NearestNeighbors
nbrs = NearestNeighbors(n_neighbors=<span class="hljs-number">2</span>, algorithm=<span class="hljs-string">'ball_tree'</span>).fit(X)
distance, indices = nbrs.kneighbors(X)
nbrs.kneighbors_graph(X).toarray() <span class="hljs-comment">#可视化</span>

<span class="hljs-comment"># 可用于监督学习</span>
<span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier
neigh = KNeighborsClassifier(n_neighbors=<span class="hljs-number">3</span>)
neigh.fix(X,y)
neigh.predit(X_test)</code></pre>
<h4 id="应用案例1异常操作检测"><a class="markdownIt-Anchor" href="#应用案例1异常操作检测"></a> 应用案例1——异常操作检测</h4>
<p>黑客入侵Web服务器后会通过系统漏洞进一步提权，搜集Linux服务器的bash操作日志，识别特定用户的操作习惯，找出异常操作行为。</p>
<p>以去重操作命令个数、最频繁的10个命令、最不常用的10个命令（以他们与整体的最频繁50个命令和最不常用50个命令的重合程度进行特征化）为特征。</p>
<pre><code class="hljs python"><span class="hljs-comment"># 统计最频繁使用的10个命令</span>
fdist = FreqDist(cmd_block).keys()
f2 = fdist[<span class="hljs-number">0</span>:<span class="hljs-number">10</span>]
f3 = fdist[<span class="hljs-number">10</span>:<span class="hljs-number">0</span>]
f2 = len(set(f2) &amp; set(dist_max))
f3 = len(set(f3) &amp; set(dist_min))</code></pre>
<p>也可以进行全量数据比较，使用词集将操作命令向量化，就是首先统计出所有出现过的命令，之后统计各命令在每个用户那里的出现此处作为向量。</p>
<h4 id="应用案例2检测rootkit"><a class="markdownIt-Anchor" href="#应用案例2检测rootkit"></a> 应用案例2——检测Rootkit</h4>
<p>一种特殊的恶意软件，它的功能是在安装目标上隐藏自身及指定的文件、进程和网络链接等信息，一般都和木马、后门等其他恶意程序结合使用。使用KDD 99数据集，识别基于telnet连接的Rootkit行为。</p>
<p>和Rootkit相关的主要特征是TCP连接的内容特征，可以筛选出来。</p>
<h4 id="应用案例3检测webshell"><a class="markdownIt-Anchor" href="#应用案例3检测webshell"></a> 应用案例3——检测Webshell</h4>
<p>使用ADFA-LD数据集中WebShell相关数据。使用词袋模型CountVectorizer。</p>
<h3 id="2-决策树"><a class="markdownIt-Anchor" href="#2-决策树"></a> 2. 决策树</h3>
<p>决策树和随机森林是常见的分类算法，尤其是决策树，判断的逻辑很多时候和人的思维非常接近。</p>
<p>随机森林指的是利用多棵树对样本进行训练并预测的一种分类器，输出的类别是由个别树输出的类别的众数而决定。</p>
<pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> tree
<span class="hljs-keyword">import</span> pydotplus
clf = tree.DecisionTreeClassifier()
clf.fit(X,Y)
<span class="hljs-comment"># 可视化</span>
dot_data = tree.export_graphviz(clf, out_file=<span class="hljs-literal">None</span>)
dot_data = pydotplus.graph_from_dot_data(dot_data)
clf.predict()

<span class="hljs-comment">#随机森林</span>
<span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier
<span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> ExtraTreesClassifier
clf2 = RandomForestClassifier(n_estimators = <span class="hljs-number">100</span>,)</code></pre>
<h3 id="应用案例1检测pop3暴力破解"><a class="markdownIt-Anchor" href="#应用案例1检测pop3暴力破解"></a> 应用案例1——检测POP3暴力破解</h3>
<p>利用“guess-passwd”、“normal”和“POP3”标记筛选出KDD99数据集中和POP3暴力破解相关的数据，挑选与POP3密码破解相关的网络特征以及TCP协议内容特征（0，4<sub>8和22</sub>30）。</p>
<h4 id="应用案例2检测ftp暴力破解"><a class="markdownIt-Anchor" href="#应用案例2检测ftp暴力破解"></a> 应用案例2——检测FTP暴力破解</h4>
<p>使用ADFA-LD数据集中FTP暴力破解相关数据，同样适用CountVectorizer词集模型进行特征化。</p>
<h3 id="3-朴素贝叶斯"><a class="markdownIt-Anchor" href="#3-朴素贝叶斯"></a> 3. 朴素贝叶斯</h3>
<p>贝叶斯分类是一系列分类算法的总称，这类算法均以贝叶斯定理为基础。其中朴素贝叶斯（Naive Bayesian, NB）是其中应用最为广泛的分类算法之一。NB算法是<strong>基于贝叶斯定理与特征条件独立假设</strong>的分类方法。</p>
<p>NB发源于古典数学理论，有着<strong>坚实的数学基础</strong>以及稳定的分类效率。同时，NB<strong>所需估计的参数很少</strong>，<strong>对缺失数据不太敏感</strong>，算法也比较<strong>简单</strong>。理论上，NB模型与其他分类方法相比具有最小的误差率。但是实际上NB模型假设属性之间相互独立，往往不成立，给模型的正确分类带来了一定影响。</p>
<p>典型算法包括高斯朴素贝叶斯（Gaussian Naive Bayes）、多项式朴素贝叶斯（Multinomial Naive Bayes）、伯努利朴素贝叶斯（Bernoulli Naive Bayes）。</p>
<p>早期垃圾邮件检测多使用朴素贝叶斯算法。</p>
<pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.naive_bayes <span class="hljs-keyword">import</span> GaussianNB
gnb = GaussianNB()</code></pre>
<h4 id="应用案例1异常操作"><a class="markdownIt-Anchor" href="#应用案例1异常操作"></a> 应用案例1——异常操作</h4>
<p>同KNN部分。</p>
<h4 id="应用案例2检测webshell"><a class="markdownIt-Anchor" href="#应用案例2检测webshell"></a> 应用案例2——检测Webshell</h4>
<p>基于Webshell的文本特征，以网上搜集的Webshell作为黑样本，当前最新wordpress源码作为白样本，一个PHP文件作为一个字符串处理，进行基于单词的2-gram切割形成词汇表，将每个PHP文件向量化。</p>
<pre><code class="hljs python"><span class="hljs-comment"># 2-gram进行切割，ignore 忽略异常字符影响，token_pattern=r'\b\w+\b'表示按单词切割</span>
webshell_bigram_vectorizer = CountVectorizer(ngram_range(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>), decode_error=<span class="hljs-string">'ignore'</span>, token_pattern=<span class="hljs-string">r'\b\w+\b'</span>, min_df =<span class="hljs-number">1</span>)
<span class="hljs-comment"># 处理白样本的时候也适用黑样本生成的词汇表进行向量化</span>
wp_bigram_vectorizer = CountVectorizer(ngram_range(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>), decode_error = <span class="hljs-string">'ignore'</span>, token_pattern = <span class="hljs-string">r'\b\w+\b'</span>, min_df=<span class="hljs-number">1</span>, vocabulary=vocabulary)</code></pre>
<p>针对函数调用建立特征，适用1-gram生成全局词汇表，基于函数和字符串常量进行切割，所以要修改token设置如下：</p>
<pre><code class="hljs python">webshell_bigram_vectorizer = CountVectorizer(ngram_range(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>), decode_error=<span class="hljs-string">'ignore'</span>, token_pattern=<span class="hljs-string">r'\b\w+\b\(|'</span>\w+\<span class="hljs-string">''</span>, min_df =<span class="hljs-number">1</span>)</code></pre>
<h4 id="应用案例3检测dga域名"><a class="markdownIt-Anchor" href="#应用案例3检测dga域名"></a> 应用案例3——检测DGA域名</h4>
<p>以Alexa为白样本，以cryptolocker和post-tovar-goz家族DGA域名为黑样本。</p>
<p>以2-gram处理DGA域名，切割单元为字符</p>
<pre><code class="hljs python">cv = CountVectorizer(ngram_range(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>), decode_error=<span class="hljs-string">'ignore'</span>,token_pattern=<span class="hljs-string">r'\w'</span>, min_df =<span class="hljs-number">1</span>)
x = cv.fit_transform(x_domain_list).toarray()</code></pre>
<h3 id="应用案例4检测针对apache的ddos攻击"><a class="markdownIt-Anchor" href="#应用案例4检测针对apache的ddos攻击"></a> 应用案例4——检测针对Apache的DDoS攻击</h3>
<p>使用KDD99数据集，筛选网络连接基本特征、基于时间的网络流量统计特征、基于主机的网络流量统计特征。</p>
<h3 id="4-逻辑回归"><a class="markdownIt-Anchor" href="#4-逻辑回归"></a> 4. 逻辑回归</h3>
<p>逻辑回归也叫回归分析，是分类和预测算法中的一种。属于线性模型。在sklearn官网可以看到相关参数，比较重要的有：</p>
<p>1）random_state；2）C：正则化系数，越小正则化程度越高；3）Solver，算法包括“newton-cg”、“lbfgs”、“liblinear”、“sag”等，默认使用“liblinear”；4）n_jobs：并发任务数。</p>
<pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression
clf = LogisticRegression(C=le5)</code></pre>
<h4 id="应用案例1java溢出攻击"><a class="markdownIt-Anchor" href="#应用案例1java溢出攻击"></a> 应用案例1——Java溢出攻击</h4>
<p>ADFA-LD数据集中Java溢出攻击相关数据，使用CountVecoriizer，使用le5逻辑回归算法。</p>
<h3 id="5-支持向量机svm"><a class="markdownIt-Anchor" href="#5-支持向量机svm"></a> 5. 支持向量机SVM</h3>
<p>基本上所有的分类问题，尤其是二分类问题，都可以先用它试下。</p>
<p>依靠核函数映射到高维空间，解决线性不可分问题。[<strong>升维和线性化</strong>]</p>
<p>应用核函数的展开定理，就不需要知道非线性映射的显式表达式；由于是在高维特征空间中建立线性学习机，所以与线性模型相比，不但几乎不增加计算的复杂性，而且在某种程度上避免了“维数灾难”。[<strong>核函数展开和计算理论</strong>]</p>
<p>常用核函数有：线性核函数、多项式核函数、径向基核函数和二层神经网络核函数。</p>
<pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> svm
clf = svm.SVC(kernel = <span class="hljs-string">'linear'</span>)
clf.fit(X,Y)
<span class="hljs-comment"># 构建超平面</span>
w = clf.coef_[<span class="hljs-number">0</span>]
a = -w[<span class="hljs-number">0</span>]/w[<span class="hljs-number">1</span>]
xx = np.linspace(<span class="hljs-number">-5</span>, <span class="hljs-number">5</span>)
yy = a * xx - (clf.intercept_[<span class="hljs-number">0</span>] / w[<span class="hljs-number">1</span>])
<span class="hljs-comment"># 支持向量</span>
b = clf.support_vectors_[<span class="hljs-number">0</span>]
yy_down = a * xx + (b[<span class="hljs-number">1</span>] - a * b[<span class="hljs-number">0</span>])
b = clf.support_vectors_[<span class="hljs-number">-1</span>]
yy_up = a * xx + (b[<span class="hljs-number">1</span>] - a * b[<span class="hljs-number">0</span>])
<span class="hljs-comment"># 画图</span>
plt.plot(xx, yy, <span class="hljs-string">'k-'</span>)
plt.plot(xx, yy_down, <span class="hljs-string">'k--'</span>)
plt.plot(xx, yy_up, <span class="hljs-string">'k--'</span>)
plt.scatter(clf.support_vectors_[:,<span class="hljs-number">0</span>], clf.support_vectors_[:,<span class="hljs-number">1</span>], s=<span class="hljs-number">80</span>, facecolors=<span class="hljs-string">'none'</span>)
plt.scatter(X[:,<span class="hljs-number">0</span>], X[:,<span class="hljs-number">1</span>], c=Y, cmap=plt.cm.Paired)
plt.axis(<span class="hljs-string">'tight'</span>)
plt.show()</code></pre>
<h4 id="应用场景1识别xss"><a class="markdownIt-Anchor" href="#应用场景1识别xss"></a> 应用场景1——识别XSS</h4>
<p>参考《基于WAVSEP的靶场搭建指南》，使用WVS等扫描器仅扫描XSS相关漏洞即可获取XSS攻击的Web日志。</p>
<p>选取Web日志中的，url长度、url中包含的第三方域名个数（http个数、https个数）、敏感字符个数（&lt;, ', &quot;, &gt;）和敏感关键字（alert, script=, onerror, onload, eval, src=）个数为特征，进行标准化（标准化、均值方差缩放、去均值）。</p>
<pre><code class="hljs python"><span class="hljs-comment"># 特征提取</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gen_len</span><span class="hljs-params">(url)</span>:</span>
    <span class="hljs-keyword">return</span> len(url)
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_url_count</span><span class="hljs-params">(url)</span>:</span>
    <span class="hljs-keyword">if</span> re.search(<span class="hljs-string">'(http://)|(https://)'</span>, url, re.IGNORECASE): <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>
    <span class="hljs-keyword">else</span>: <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_evil_char</span><span class="hljs-params">(url)</span>:</span>
    <span class="hljs-keyword">return</span> len(re.findall(<span class="hljs-string">"[&lt;&gt;,\'\"/]"</span>, url, re.IGNORECASE))
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_evil_word</span><span class="hljs-params">(url)</span>:</span>
    <span class="hljs-keyword">return</span> len(re.findall(<span class="hljs-string">"(alert)|(script=)(%3c)|(%3e)|(%20)|(onerror)|(onload)|(eval)|(src=)|(prompt)"</span>,url, re.IGNORECASE))
<span class="hljs-comment"># 模型存储</span>
joblib.dump(clf, <span class="hljs-string">"xss-svm-2000-module.m"</span>)
clf = joblib.load(<span class="hljs-string">"xss-svm-2000-module.m"</span>)</code></pre>
<h4 id="应用场景2dga域名"><a class="markdownIt-Anchor" href="#应用场景2dga域名"></a> 应用场景2——DGA域名</h4>
<p>使用元音字母个数、去重后字母数字个数与域名长度比例、平均jarccard系数（两个域名之间）、HMM系数为特征。</p>
<p>将这些特征分布情况（纵轴为特征，横轴为域名长度）作图。</p>
<h3 id="6-k-means和dbscan"><a class="markdownIt-Anchor" href="#6-k-means和dbscan"></a> 6. K-Means和DBSCAN</h3>
<p>K-Means算法是最经典的基于划分的聚类方法，以空间中k个点为中心进行聚类，通过迭代的方法，逐次更新各聚类中心的值，直至得到最好的聚类结果。</p>
<pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> K-Means
y_pred = KMeans(n_clusters=<span class="hljs-number">3</span>, random_state=random_state).fit_predict(X)
plt.scatter(X[:<span class="hljs-number">0</span>], X[:<span class="hljs-number">1</span>], c=y_pred)
plt.show()</code></pre>
<p>DBSCAN是一个比较有代表性的基于密度的聚类算法，与划分和层次聚类方法不同，它将簇定义为密度相连的点的最大集合，能够把具有足够高密度的区域划分为簇，并可在噪声的空间数据库中发现任意形状的聚类。<strong>不需要事先知道要形成的簇类的数量</strong>，就可以发现任意形状的簇类，并能够识别出噪声点。</p>
<p>DBSCAN核心参数为：1）eps，同一聚类集合两个样本的最大距离；2）min_samples，同一集合中最小样本数；3）algorithm，分为’auto‘，’ball_tree’，‘kd_tree’，‘brute’；4）leaf_size，使用BallTree或cKDTree算法的叶子节点数；5）n_jobs，并发任务数。</p>
<pre><code class="hljs python"><span class="hljs-comment"># 聚类与可视化</span>
<span class="hljs-keyword">import</span> sklearn.cluster <span class="hljs-keyword">import</span> DBSCAN
db = DBSCAN (eps=<span class="hljs-number">0.3</span>, min_samples=<span class="hljs-number">10</span>).fit(X)
core_samples_mask = np.zeros_like(db.labels_, dtype=bool)
core_sampls_mask[db.core_sample_indices_] = <span class="hljs-literal">True</span>
labels = db.labels_
colors = plt.cm.Spectral(np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, len(unique_labels)))
<span class="hljs-keyword">for</span> k, col <span class="hljs-keyword">in</span> zip(unique_labels, colors):
    <span class="hljs-keyword">if</span> k == <span class="hljs-number">-1</span>:
        col = <span class="hljs-string">'k'</span>
    class_member_mask = (labels == k)
    xy = X[class_member_mask &amp; core_samples_mask]
    plt.plot(xy[:,<span class="hljs-number">0</span>], xy[:,<span class="hljs-number">1</span>], <span class="hljs-string">'o'</span>, markerfacecolor=col, markeredgecolor=<span class="hljs-string">'k'</span>, markersize=<span class="hljs-number">14</span>)
    xy = X[class_member_mask &amp; ~core_samples_mask]
plt.plot(xy[:,<span class="hljs-number">0</span>], xy[:,<span class="hljs-number">1</span>], <span class="hljs-string">'o'</span>, markerfacecolor=col, markeredgecolor=<span class="hljs-string">'k'</span>, markersize=<span class="hljs-number">6</span>)
plt.show()</code></pre>
<h4 id="应用案例检测dga"><a class="markdownIt-Anchor" href="#应用案例检测dga"></a> 应用案例——检测DGA</h4>
<p>同上文一样，以2-gram分割域名，进行词表映射。</p>
<p>可视化的时候使用TSNE作图。</p>
<pre><code class="hljs python">tsne = TSNE(learning_rate=<span class="hljs-number">100</span>)
x = tsne.fit_transform(x)
<span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> enumerate(X):
    x1, x2 = x[i]
    <span class="hljs-keyword">if</span> y_pred[i] == <span class="hljs-number">1</span>:
        plt.scatter(x1, x2, marker=<span class="hljs-string">'o'</span>)
    <span class="hljs-keyword">else</span>:
        plt.scatter(x1, x2, marker=<span class="hljs-string">'x'</span>)
    plt.show()</code></pre>
<h3 id="7-fp-growth-和-apriori"><a class="markdownIt-Anchor" href="#7-fp-growth-和-apriori"></a> 7. FP-growth 和 Apriori</h3>
<p>关联算法，无监督算法，自动从数据中挖掘出潜在的关联关系。</p>
<p>三个基本概念：支持度、置信度、频繁k项集。</p>
<ul>
<li>支持度，既有A又有B的概率，它表现的是A和B两个事件相对整个数据集合同时发生的频繁程度；</li>
<li>置信度，AB两个事件的相关程度，比如尿布和啤酒的置信度为0.8，表明在同时购买了两者的消费者中，购买尿布的80%又购买了啤酒。不满足交换律；</li>
<li>频繁k项集，满足最小支持度阈值的事件称为频繁k项集；</li>
</ul>
<p><strong>Apriori算法</strong>挖掘同时满足最小支持度阈值和最小置信度阈值的关联规则。使用频繁项集的先验知识，以一种称为“逐层搜索”的迭代方法，k项集用于探索（k+1）项集。任一频繁项集的所有非空子集也必须是频繁的。</p>
<p>主流的机器学习库对Apriori支持很少，但可以找到开源实现。</p>
<p>安全领域的Aprior应用非常广泛，比如挖掘关联WAF的accesslog与后端数据库的sqllog，识别SSH操作日志中异常操作等。</p>
<p><strong>FP-growth算法</strong>基于Apriori构建，采用了高级的数据结构减少扫描次数，大大加快了算法速度。FP-growth算法只需要对数据库进行两次扫描，而Apriori算法对于每个潜在的频繁项集都会扫描数据集判定给定模式是否频繁。</p>
<p>基本过程包括构建FP树和从FP树中挖掘频繁项集。</p>
<p>一棵FP树通过链接来连接相似元素，被连起来的元素项可以看成一个链表。一个元素项可以在一棵FP树种出现多次。FP树的解读方式是读取某个节点开始到根节点的路径。路径上的元素构成一个频繁项集，开始节点的值表示这个项集的支持度。FP树中会多次出现相同的元素项，也是因为同一个元素项会存在于多条路径，构成多个频繁项集。但是频繁项集的共享路径是会合并的。取一个最小阈值，出现次数低于最小阈值的元素项将被直接忽略。</p>
<p>名气较大的开源实现是<strong>pyfpgrowth</strong>，support代表支持度，minConf代表置信度。</p>
<pre><code class="hljs python">patterns = pyfpgrowth.find_frequent_patterns(transactions, support)
rules = pyfpgrowth.generate_association_rules(patterns, minConf)</code></pre>
<h4 id="应用案例1xss相关参数"><a class="markdownIt-Anchor" href="#应用案例1xss相关参数"></a> 应用案例1——XSS相关参数</h4>
<p>以xssed网站样例以及WAF的拦截日志中提取XSS攻击日志为样本，目标是分析出潜在关联关系，作为SVM、KNN等算法的特征提取依据。将每行日志文本按照一定分隔符切割成单词向量，完成向量化。</p>
<p>以十分严格的置信度运行（0.99）试图找到关联关系接近100%的情况。将支持度也下降到0.001，这意味着即使对应的关联关系出现的概率只有千分之一，只要它对应的是强关联，置信度超过0.99，我们也认为这是一种有价值的关联。</p>
<p>筛选结果，形成对应举例。</p>
<h4 id="应用案例2挖掘疑似僵尸主机"><a class="markdownIt-Anchor" href="#应用案例2挖掘疑似僵尸主机"></a> 应用案例2——挖掘疑似僵尸主机</h4>
<p>僵尸主机频繁更换IP难以挖掘，使用FP-growth分析防火墙拦截日志，挖掘浏览器的user-agent字段和被攻击目标URL之间的关联关系，<strong>初步确定</strong>潜在的僵尸主机。</p>
<h3 id="8-隐式马尔科夫模型"><a class="markdownIt-Anchor" href="#8-隐式马尔科夫模型"></a> 8. 隐式马尔科夫模型</h3>
<p>特别适合处理时序数据，挖掘时序数据前后的关系。在网络安全领域也广泛存在时序数据，比如网站的访问顺序、系统调用的顺序、管理员的操作命令等。</p>
<p>隐式马尔可夫模型（Hidden Markov Model, HMM）的<strong>基础假设</strong>是，一个连续的时间序列事件，它的状态由且仅由它前面的N个事件决定，对应的时间序列可以成为<strong>N阶马尔可夫链</strong>。需要通过可观察序列推测隐藏序列，就是隐式。</p>
<p><strong>HMMLearn</strong>是Python下的一个HMM实现，是从Scikit-Learn独立出来的一个项目。</p>
<pre><code class="hljs python"><span class="hljs-keyword">from</span> hmmlearn <span class="hljs-keyword">import</span> hmm
<span class="hljs-comment"># 训练</span>
l = hmm.GaussianHMM(n_components=<span class="hljs-number">4</span>, covariance_type=<span class="hljs-string">'full'</span>)
model.startprob_ = startprob
model.transmat_ = transmat
model.means_ = means
model.covars_ = covars
<span class="hljs-comment"># 可视化</span>
X, Z = model.sample(<span class="hljs-number">500</span>)
plt.plot(X[:, <span class="hljs-number">0</span>], X[:, <span class="hljs-number">1</span>], <span class="hljs-string">".-"</span>, label=<span class="hljs-string">"observations"</span>, ms=<span class="hljs-number">6</span>,
         mfc=<span class="hljs-string">"orange"</span>, alpha=<span class="hljs-number">0.7</span>)
<span class="hljs-keyword">for</span> i, m <span class="hljs-keyword">in</span> enumerate(means):
    plt.text(m[<span class="hljs-number">0</span>], m[<span class="hljs-number">1</span>], <span class="hljs-string">'Component %i'</span> % (i + <span class="hljs-number">1</span>),
             size=<span class="hljs-number">17</span>, horizontalalignment=<span class="hljs-string">'center'</span>,
             bbox=dict(alpha=<span class="hljs-number">.7</span>, facecolor=<span class="hljs-string">'w'</span>))
plt.legend(loc=<span class="hljs-string">'best'</span>)
plt.show()</code></pre>
<div align="center">
  <img src="/2021/06/29/dou-brother/hmm.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>HMM模型完成训练后通常可以<strong>解决3大类问题</strong>：</p>
<ul>
<li>输入观察序列获取概率最大的隐藏序列，最典型的应用就是语音解码以及词性标注；</li>
<li>输入部分观察序列预测概率最大的下一个值，比如搜索词猜想补齐等；</li>
<li>输入观察序列获取概率，从而判断观察序列的合法性。参数异常检测就输入第三种。</li>
</ul>
<h4 id="应用案例1识别xss攻击"><a class="markdownIt-Anchor" href="#应用案例1识别xss攻击"></a> 应用案例1——识别XSS攻击</h4>
<p>两种检测思路；第一种是学习正常业务模型识别异常；第二种是学习攻击模型进一步识别满足攻击语法的攻击行为。</p>
<p>正常的http请求中参数的取值范围都是确定的，可以用字母数字特殊字符来表示。</p>
<p>隐藏序列S1～S4四个状态间循环转化，概率符合<strong>转移概率矩阵</strong>，同时四个状态都有确定的概率，以观察序列中的A、C、N、T 4个状态展现，这个转换的概率称为<strong>发射概率矩阵</strong>。<strong>HMM建模过程就是通过学习样本，生成这两个矩阵的过程</strong>。</p>
<p>HMM的使用方式是通过学习正常来识别异常，即通常说的“以白找黑”。缺点是扫描器访问、代码异常、用户的错误操作、业务代码的升级等，都会产生大量误报。</p>
<p>目前另外一种开始流行的方法是，通过学习攻击报文，训练攻击模型，然后“以黑找黑”。这种方法虽然理论上可能会遗漏真实攻击，但是结果更加可控，可以达到可运维状态。</p>
<p><em>需要X_lens的原因是参数样本的长度可能不一致，所以需要单独输入。</em></p>
<h4 id="应用案例2识别dga域名"><a class="markdownIt-Anchor" href="#应用案例2识别dga域名"></a> 应用案例2——识别DGA域名</h4>
<p>HMM作为DGA僵尸网络区分的一个变量，非常具有区分性。</p>
<h3 id="9-图算法与知识图谱"><a class="markdownIt-Anchor" href="#9-图算法与知识图谱"></a> 9. 图算法与知识图谱</h3>
<p>网络安全领域在风控、威胁情报方面有很多非结构化网状数据，所以会用到图算法。</p>
<p>Neo4j是一个高性能的图形数据库，将结构化数据存储在网络上而不是表中，具有嵌入式、高性能、轻量级等优势，可进行关联关系展现。</p>
<h4 id="应用实例1识别webshell"><a class="markdownIt-Anchor" href="#应用实例1识别webshell"></a> 应用实例1——识别Webshell</h4>
<p>WebShell具有很多访问特征，其中和有向图相关的为：1）入度出度均为0；2）入度出度均为1且自己指向自己。</p>
<p>在生产环境实际使用中，我们遇到的误报分为以下几种（这个在科研论文中也要加以讨论）。</p>
<h4 id="应用实例2僵尸网络识别"><a class="markdownIt-Anchor" href="#应用实例2僵尸网络识别"></a> 应用实例2——僵尸网络识别</h4>
<p>定义阈值R，攻击的域名超过R的IP才列入统计范围。</p>
<p>定义计算jarccard系数的函数，作为衡量两个IP攻击集合相似度的方式，当两个IP攻击的域名jarccard大于等于N时才列入统计范围。</p>
<h4 id="应用实例3安全知识图谱"><a class="markdownIt-Anchor" href="#应用实例3安全知识图谱"></a> 应用实例3——安全知识图谱</h4>
<p>在安全领域应用知识图谱，可以挖掘数据之间潜在的联系，结合这些潜在的联系可以大大扩展我们的数据分析思路。</p>
<p>在风控领域有较多应用，如<strong>盗号检测、撞库攻击、刷单检测、威胁情报分析</strong>等。</p>
<p>撞库是黑客通过收集互联网已泄露的用户和密码信息，生成对应的字典表，尝试批量登录其他网站后，得到一系列可以登录的用户。</p>
<p>刷单一般可分为两种：一是单品刷销量为做爆款等做准备；二是刷信誉以提高店铺整体信誉度。还有一种刷单更为直接，以外卖软件为例子，同一个人使用两台手机，分别安装客户下单软件和商家接单软件，一下一接，捞取补贴。</p>
<p>在2016年的RSA大会上出现了<strong>10家威胁情报公司</strong>，其中包括老牌安全公司Symantec、Dell Security，也包括大量新秀如Webroot、CrowdStrike，其中还包含国内的一家创业公司ThreatBook。</p>
<p>可以<strong>挖掘后门文件间的关系</strong>。黑产通常通过传播后门文件入侵主机，组织起庞大的僵尸网络。后门文件通常通过连接C&amp;C服务器的域名来监听控制指令，后门文件中硬编码少量C&amp;C服务器的域名，然后自动化下载最近的C&amp;C服务器列表。通过静态分析后门文件中硬编码的域名，关联分析域名和文件之间的关系，可以挖掘出后门文件之间的潜在联系。</p>
<p>挖掘域名潜在联系，黑产通常会注册大量的域名用于C&amp;C服务器、钓鱼等，注册域名时会登记注册人的邮箱信息，通过关联IP、注册邮箱、域名可以挖掘潜在的关联关系。</p>
<h3 id="10-神经网络算法"><a class="markdownIt-Anchor" href="#10-神经网络算法"></a> 10. 神经网络算法</h3>
<p>浅层学习使用时，需要花费至少一半的时间在数据清洗与特征提取上，即特征工程。</p>
<pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.neural_network <span class="hljs-keyword">import</span> MLPClassifier
clf = MLPClassifier(solver=<span class="hljs-string">'lbfgs'</span>, alpha=le<span class="hljs-number">-5</span>, hidden_layer_sizes=(<span class="hljs-number">5</span>,<span class="hljs-number">2</span>), random_state=<span class="hljs-number">1</span>)
clf.fit()</code></pre>
<h4 id="应用案例1垃圾邮件"><a class="markdownIt-Anchor" href="#应用案例1垃圾邮件"></a> 应用案例1——垃圾邮件</h4>
<p>SpamBase这个入门级的垃圾邮件，直接跑了个DNN。</p>
<h4 id="应用案例2恶意评论"><a class="markdownIt-Anchor" href="#应用案例2恶意评论"></a> 应用案例2——恶意评论</h4>
<p>使用RNN处理Movie Review Data数据集</p>
<h4 id="应用案例3识别webshell"><a class="markdownIt-Anchor" href="#应用案例3识别webshell"></a> 应用案例3——识别Webshell</h4>
<h4 id="应用案例4生成常用密码"><a class="markdownIt-Anchor" href="#应用案例4生成常用密码"></a> 应用案例4——生成常用密码</h4>
<p>调用sklearn的序列生成器，分别设置不同的新颖度Temperature来生成密码。</p>
<h1 id="web安全之深度学习入门"><a class="markdownIt-Anchor" href="#web安全之深度学习入门"></a> 《Web安全之深度学习入门》</h1>
<h2 id="一-背景介绍"><a class="markdownIt-Anchor" href="#一-背景介绍"></a> 一. 背景介绍</h2>
<p>TFLearn是一个模块化和透明的深度学习库，构建在TensorFlow之上，它为TensorFlow提供高层次API，目的是快速搭建试验环境，同时保持对TensorFlow的完全透明和兼容性。</p>
<p>在CNN出现之前，图像分类算法依赖于复杂的特征工程。常用的特征提取方法包括SIFT（Scale-Invariant Feature Transform，尺度不变特征转换）、HOG（Histogram of Oriented Gradient，方向梯度直方图）、LBP（Local BianrayPattern，局部二值模式）等，常用的分类算法为SVM。</p>
<p>AlexNet、VGG等网络架构实现。</p>
<p>可以使用一维的卷积函数处理文字片段，提炼高级特征进行进一步分析。</p>
<p>序列生成是RNN非常有意思的一类应用，机器学习专家通过使用RNN<strong>学习大量Java源码和Linux内核源码</strong>，生成的Java代码和Linux内核源码几乎都可以编译通过。</p>
<p>序列生成中使用最多的是<strong>char RNN模型</strong>，以字符为最小的单元，把每个字符当做一个输入，这样一个单词、一句话甚至一篇文章都可以看成由字符组成的一个序列，通常这样的字符集合会包括字母、数字和常用标点。RNN本质上只能理解数字序列，所以需要建立一个映射关系，把字符映射成数字，这映射关系称为char-idx。</p>
<p>自然语言分析技术大致分为3个层面：词法分析、句法分析和语义分析。</p>
<p>CRF是一种概率化结构模型，可以看做是一个概率无向图模型，节点表示随机变量，边表示随机变量之间的概率依赖关系。</p>
<p>Seq2seq任务，使用编码器-解码器架构，在编码阶段将整个源序列编码成一个向量，在解码阶段通过最大化预测序列概率，从中解码出整个目标序列。</p>
<p><strong>OpenSOC是思科公司</strong>2014年在BroCon大会上公布的开源项目，但是没有真正开源其源代码，只是发布了其技术框架。主要由数据源系统、数据收集层、消息系统层、实时处理层、存储层、分析处理层组成。目前OpenSOC已经加入Apache工程改名为Apache Metron。</p>
<div align="center">
  <img src="/2021/06/29/dou-brother/metron.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<p>相关数据如下所示：</p>
<ul>
<li>网络流量主要分为网络全流量和Netflow两种，网络全流量包含完整的网络数据，包含TCP/IP协议栈的数据，比如MAC头、IP头、TCP头、HTTP头以及HTTP载荷数据；常见获取方式为交换机镜像、分光镜和网络分流器3种。分光器成本低廉，并且特性稳定，是大型网络中流量复制的首选方案。但是也有其局限性，比如当光衰过大时无法使用。另外，如果网络中存在一定的电口链路，也是无法使用分光器进行流量复制的。这个时候就需要使用专用的流量复制设备——网络分流器（Network Tap）。Netflow常见的版本包括数据流时戳、源IP地址和目的IP地址、源端口号和目的端口号、输入接口号和输出接口号、下一跳IP地址、信息流中的总字节数和信息流中的数据包数量。</li>
<li>日志文件</li>
<li>Syslog是在一个网络中转发系统日志信息的标准，可用它记录设备的日志</li>
<li>SNMP是基于TCP/IP协议族的网络管理标准，是一种在网络中管理网络节点（如服务器、工作站、路由器、交换机等）的标准协议。SNMP能够使网络管理员提高网络管理效能，及时发现并解决网络问题以及规划网络的增长。网络管理员还可以通过SNMP接收网络节点的通知消息以及告警事件报告等来获知网络出现的问题。常见的网络设备都支持把日志和报警以SNMP的形式发送出来，通常把主动发送SNMP称为SNMP trap。</li>
<li>JDBC是一种用于执行SQL语句的Java API，可以为多种关系数据库提供统一访问，它由一组用Java语言编写的类和接口组成</li>
<li>爬虫</li>
</ul>
<p>数据收集层常用软件包括Logstash和Flume，针对网络全流量收集还有Bro。其中Logstash和Flume功能完全一样，选择一个即可。<strong>Logstash</strong>常用于日志处理，包括Inputs、Filters和Outputs。</p>
<p><strong>Bro是一款被动的开源流量分析器</strong>，主要用于对链路上所有深层次的可疑行为流量进行安全监控，为网络流量分析提供了一个综合平台，特别侧重于语义安全监控。Bro的目标在于搜寻攻击活动并提供其背景信息与使用模式。</p>
<p><strong>最常使用的消息系统是Kafka</strong>。Kafka是一种高吞吐量的分布式发布、订阅消息系统。系统由 Broker、topic、partition、Producer、consumer、Consumer Group组成。Kafka的正常运行需要依赖ZooKeeper, Kafka的安装包里默认会包含ZooKeeper。</p>
<p><strong>实时处理层主要使用Storm</strong>, Storm是一个免费开源、分布式、高容错的实时计算系统。Storm经常用于实时分析、在线机器学习、持续计算、分布式远程调用和ETL等领域。主要分为两种组件Nimbus和Supervisor，这两种组件本地都不保存状态，任务状态和心跳信息等都保存在ZooKeeper上。</p>
<p>Hadoop分布式文件系统（HDFS）被设计成适合运行在通用硬件上的分布式文件系统。HBase是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBase技术可在廉价PC Server上搭建起大规模结构化存储集群。HBase是GoogleBigtable的开源实现。Pig和Hive还为HBase提供了高层语言支持，使得在HBase上进行数据统计处理变得非常简单。Sqoop则为HBase提供了方便的RDBMS数据导入功能，使得传统数据库数据向HBase中迁移变得非常方便。</p>
<p>Elasticsearch是一个基于Lucene的搜索服务，它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful的Web接口。</p>
<p>Apache Spark是专为大规模数据处理而设计的快速通用的计算引擎。</p>
<p><strong>Spark</strong>拥有Hadoop MapReduce所具有的优点，但不同于MapReduce的是，Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。与Hadoop不同，Spark和Scala能够紧密集成，其中的Scala可以像操作本地集合对象一样轻松地操作分布式数据集。Spark基于内存的计算模型天生就擅长迭代计算，多个步骤计算直接在内存中完成，只有在必要时才会操作磁盘和网络，所以说Spark正是机器学习的理想的平台。MLlib目前支持4种常见的机器学习问题：分类、回归、聚类和协同过滤。MLlib基于RDD，天生就可以与Spark SQL、GraphX、Spark Streaming无缝集成。</p>
<p><strong>ELK架构</strong>。</p>
<div align="center">
  <img src="/2021/06/29/dou-brother/frame.jpg" srcset="/img/loading.gif" width="30%" height="30%" alt="oauth">
</div>
<div align="center">
  <img src="/2021/06/29/dou-brother/kafa.jpg" srcset="/img/loading.gif" width="40%" height="40%" alt="oauth">
</div>
<h2 id="二-相关数据集"><a class="markdownIt-Anchor" href="#二-相关数据集"></a> 二. 相关数据集</h2>
<ul>
<li>垃圾邮件，Enron-Spam数据集，都是真实环境下的真实邮件，非常具有实际意义。</li>
<li>互联网电影资料库（Internet Movie Database, IMDB）</li>
<li>SMS Spam Collection数据集骚扰短信，真实短信内容，包括4831条正常短信和747条骚扰短信。</li>
<li>SEA数据集，恶意操作</li>
<li>在Github上可以搜索一些Webshell样本</li>
<li>MIST数据集Malware Instruction Set for Behaviour Analysis，通过分析大量的恶意程序，提取静态的文件特征以及动态的程序行为特征，特征提取主要使用CWSandbox，MIST目前包含的恶意程序如下，主要分为APT、Crypto、Locker和Zeus。</li>
<li>Kaggle恶意软件数据集500G。</li>
<li>Kaggle Credit Card Fraud Detection数据集，极不平衡，诈骗频率只占交易频次0.172%。</li>
</ul>
<p>之后的章节基本上是对每个场景，提取特征，之后使用SVM、NV、MLP、RNN、CNN等进行处理。</p>
<h2 id="三-一些算法"><a class="markdownIt-Anchor" href="#三-一些算法"></a> 三. 一些算法</h2>
<p>TF-IDF，Word2vec，Doc2vec</p>
<p>XGBoost</p>
<h2 id="四-垃圾邮件识别"><a class="markdownIt-Anchor" href="#四-垃圾邮件识别"></a> 四. 垃圾邮件识别</h2>
<p>为了抵御垃圾邮件侵扰，通常会使用商用的邮件安全解决方案，常见的国外厂商包括Cisco、Blue Coat、Websense、Zscaler以及McAfee。</p>
<p>词袋、词集模型。借鉴了词袋模型的思想，使用生成的词汇表对原有句子按照单词逐个进行编码，tensorflow默认支持这种方式。</p>
<p>TF-IDF，字词的重要性与它在文件中出现的次数成正比，但同时与它在语料库中出现的频率成反比。TF表示词条在文档d中出现的频率。逆向文件频率（inverse document frequency, IDF）的主要思想是：如果包含词条t的文档越少，也就是n越小，IDF越大，则说明词条t具有很好的类别区分能力。TF-IDF模型<strong>通常和词袋模型配合使用</strong>，对词袋模型生成的数组进一步处理。</p>
<p>在朴素贝叶斯的实验中我们发现，并非词袋抽取的单词个数越多，垃圾邮件识别概率越大，而是有个中间点可以达到效果最佳，并且TF-IDF结合词袋模型会提升检测能力。</p>
<h2 id="五-恶意评论"><a class="markdownIt-Anchor" href="#五-恶意评论"></a> 五. 恶意评论</h2>
<p>使用Scikit-Learn的CountVectorizer对象进行词袋化处理，同时将抽取的词汇表保存，用于词袋化测试数据集。词汇表保存在CountVectorizer对象的vocabulary属性中，初始化CountVectorizer对象。其中有几个非常重要的参数。</p>
<p>借鉴了词袋模型的思想，使用生成的词汇表对原有句子按照单词逐个进行编码。在本例中，使用TensorFlow的tflearn.data_utils.VocabularyProcessor函数即可</p>
<p>CBOW模型能够根据输入周围n-1个词来预测出这个词本身，而Skip-gram模型能够根据词本身来预测周围有哪些词。Word2Vec最常用的开源实现之一就是gensim。参数min_count可以对字典做截断，出现少于min_count次数的单词会被丢弃掉；神经网络的隐藏层的单元数，推荐值为几十到几百。gensim的官方文档中强调增加训练次数可以提高生成的Word2Vec的质量，可以通过设置epochs参数来提高训练次数，默认的训练次数为5。</p>
<p>一部分单词找不到对应的Word2Vec。需要捕捉这个异常，通常使用python的KeyError异常捕捉即可。</p>
<p><strong>Doc2Vec</strong>原理与Word2Vec相同，分为分布式存储（DistributedMemory, DM）和分布式词袋（Distributed Bag of Words, DBOW）。Doc2Vec处理的每个英文段落，需要使用一个唯一的标识来标记，并且使用一种特殊定义的数据格式保存需要处理的英文段落。以英文段落为单位。为了提高效率，可以把之前训练得到的Word2Vec和Doc2Vec模型保存成文件形式。</p>
<h2 id="六-骚扰短信识别"><a class="markdownIt-Anchor" href="#六-骚扰短信识别"></a> 六. 骚扰短信识别</h2>
<p>特征提取处理流程和上文相同。</p>
<pre><code class="hljs python">vectorizer = CountVectorizer(
                             decode_error=<span class="hljs-string">'ignore'</span>,
                             strip_accents=<span class="hljs-string">'ascii'</span>,
                             max_features=max_features,
                             stop_words=<span class="hljs-string">'english'</span>,
                             max_df=<span class="hljs-number">1.0</span>,
                             min_df=<span class="hljs-number">1</span> )
<span class="hljs-keyword">print</span> vectorizer
x_train=vectorizer.fit_transform(x_train)
x_train=x_train.toarray()
vocabulary=vectorizer.vocabulary_

<span class="hljs-comment"># tensorflow支持的词汇表模型</span>
vp=tflearn.data_utils.VocabularyProcessor(max_document_length=max_document_length,
                                          min_frequency=<span class="hljs-number">0</span>,
                                          vocabulary=<span class="hljs-literal">None</span>,
                                          tokenizer_fn=<span class="hljs-literal">None</span>)
x_train=vp.fit_transform(x_train, unused_y=<span class="hljs-literal">None</span>)
x_train=np.array(list(x_train))</code></pre>
<p>Word2vec训练完成后，单词对应的Word2Vec会保存在model变量中，可以使用类似字典的方式直接访问。一句话或者几个单词组成的短语含义可以通过把全部单词的Word2Vec值相加取平均值来获取。再做一步数据标准化。</p>
<p>XGBoost的支持Scikit-Learn风格的API接口，完全可以当做一个加强版的决策树来使用。</p>
<h2 id="七-linux后门检测"><a class="markdownIt-Anchor" href="#七-linux后门检测"></a> 七. Linux后门检测</h2>
<p>使用3-gram处理，TF-IDF提升分类性能，</p>
<h2 id="八-用户行为分析与恶意行为检测"><a class="markdownIt-Anchor" href="#八-用户行为分析与恶意行为检测"></a> 八. 用户行为分析与恶意行为检测</h2>
<p>将恶意内部人员和内部员工的异常操作统称为恶意操作。用户行为分析（User Behawiors Analysis, UBA），可提供以往被遗漏的数据保护和欺诈检测功能。</p>
<h2 id="九-webshell检测"><a class="markdownIt-Anchor" href="#九-webshell检测"></a> 九. WebShell检测</h2>
<p>“Web”的含义是需要服务器提供Web服务，“Shell”的含义是取得对服务器某种程度的操作权限。WebShell常常被入侵者利用，通过网站服务端口对网站服务器获取某种程度的操作权限。</p>
<p>常见Webshell检测方法有：</p>
<ul>
<li>静态检测，通过匹配特征码、特征值、危险操作函数来查找。只能查找已知的WebShell，并且误报率、漏报率会比较高。</li>
<li>动态检测，基于检测执行时刻表现出来的特征，比如数据库操作、敏感文件读取等。</li>
<li>语法检测，根据PHP语言扫描编译的实现方式，进行剥离代码和注释，通过分析变量、函数、字符串、语言结构的方式，来实现关键危险函数的捕捉。</li>
<li>统计学检测，通过信息熵、最长单词、重合指数、压缩比等进行检测。</li>
</ul>
<p>以WordPress、PHPCMS、Smarty、Yii等使用PHP开发的应用为白样本。</p>
<h2 id="十-智能扫描器"><a class="markdownIt-Anchor" href="#十-智能扫描器"></a> 十. 智能扫描器</h2>
<p>扫描器通过对目标网站发送攻击请求，根据应答内容判断是否存在漏洞，整个过程就是模拟黑客踩点和渗透的过程，常见的开源扫描器有Nikto、Paros proxy、Weblnspect、OWASP ZAP、WebScarab、Burpsuite等。</p>
<p>靶场，可以理解为人为搭建的具有各种Web漏洞的网站，主要用于测试Web扫描器、IDS、WAF以及进行攻防演练。比如WAVSEP。</p>
<p>是否可以让机器通过学习攻击样本，自动生成攻击载荷，而不是死板地照套模板规则呢？这个基本是RNN序列生成问题。</p>
<p>《Method of Detecting Vulnerability in Web apps using machine learning》</p>
<p>是否可以让机器自动识别登录页面并自动识别参数进行登录呢？</p>
<h2 id="十一恶意程序识别"><a class="markdownIt-Anchor" href="#十一恶意程序识别"></a> 十一.恶意程序识别</h2>
<p>将整个文件以字符串的形式保存，会用空格替换一些关键字。给不同种类的恶意软件分配对应的标签。</p>
<p>以单词为单位切分文件，提取N-Gram特征。</p>
<p>使用TF-IDF进一步处理，提升算法分类性能。</p>
<p>随机划分训练集、测试集。训练、测试、验证。</p>
<h2 id="十二-反对信用卡欺诈"><a class="markdownIt-Anchor" href="#十二-反对信用卡欺诈"></a> 十二. 反对信用卡欺诈</h2>
<p>常见的信用卡欺诈主要包括：</p>
<ul>
<li>失卡冒用：一是发卡银行在向持卡人寄卡时丢失，即未达卡；二是持卡人自己保管不善丢失；三是被不法分子窃取。</li>
<li>假冒申请：利用他人资料申请信用卡，或是故意填写虚假资料。最常见的是伪造身份证，填报虚假单位或家庭地址。</li>
<li>伪造信用卡：团伙做案，从盗取卡资料、制造假卡、贩卖假卡，到用假卡作案。伪造者经常利用一些最新的科技手段盗取真实的信用卡资料，有些是用微型测录机窃取信用卡资料，有些是伺机偷改授权机终端功能窃取信用卡资料，当窃取真实的信用卡资料后，便进行批量性的制造假卡，然后通过贩卖假卡大肆作案，牟取暴利。</li>
</ul>
<p>黑白样本的比例完全失衡，解决此类问题存在两种方法：</p>
<ul>
<li>降采样，就是从数据量占优势的数据集中随机选取一定数量的样本，通常选择的数量与数据量小的样本数量相当。比如使用np.random.choice函数随机选取。</li>
<li>过采样，保留数量占优势的样本，通过一定的算法，在数量较少样本的基础上生成新样本。常见的生成算法是<strong>Smote</strong>。</li>
</ul>
<p>Smote思想：1）随机选定n个少类样本；2）找出最靠近它的m个少类样本；3）任选最临近的m个少类样本中的任意一点，在两点上任选一点就是新增的数据样本。<strong>Python实现是imblearn</strong>。</p>
<h1 id="web安全之强化学习与gan"><a class="markdownIt-Anchor" href="#web安全之强化学习与gan"></a> 《Web安全之强化学习与GAN》</h1>
<p>网络安全专家一直试图把自己对网络威胁的理解转换成机器可以理解的方式，比如黑白名单、正则表达式，然后利用机器强大的计算能力从流量、日志、文件中寻找似曾相识的各类威胁。</p>
<h2 id="一-背景"><a class="markdownIt-Anchor" href="#一-背景"></a> 一. 背景</h2>
<p>在2017年的BlackHat安全会议上，阿里巴巴安全部门的研究人员演示了用声音和超声攻击依赖于陀螺仪、加速度计等微机电系统传感器输入信号的智能设备。AI设备的安全显然是AI安全的一个重要领域。</p>
<p>AI安全大体可以归纳为4类：AI设备的安全、AI模型的安全、使用AI进行安全建设以及使用AI发起攻击。</p>
<p>OpenAI Gym是一款用于研发和比较强化学习算法的工具包，其中包括了各种环境，目前有模拟的机器人学任务、桌面游戏、多位数加法之类的计算任务等。Keras-rl是Keras的一套强化学习库。</p>
<p><strong>XGBoost</strong>所应用的算法就是梯度提升决策树，既可以用于分类也可以用于回归问题中。XGBoost最大的特点在于，它能够自动利用CPU的多线程进行并行计算，同时在算法上加以改进，提高了精度。</p>
<p><strong>集成学习的思路</strong>是通过对多个分类器的分类结果进行某种组合来决定最终的分类，以取得比单个分类器更好的性能。可以分为两类：第一类是个体学习器之间存在强依赖关系，一系列个体学习器基本都需要串行生成，代表算法是Boosting系列算法（adaboost和GBDT）；第二类是个体学习器之间不存在强依赖关系，一系列个体学习器可以并行生成，代表算法是Bagging和随机森林（Random Forest）系列算法。</p>
<p><strong>Keras</strong>有两种类型的模型：序列模型（Sequential）和函数式模型（Model）。前者比较常见，函数式模型更为通用，序列模型是函数式模型的一种特殊情况。还可以<strong>支持多进多出</strong>的情况。网络可视化方法plot_model。</p>
<ul>
<li>Dense层，全连接；</li>
<li>activation层，relu、leakyrelu、tanh、sigmoid</li>
<li>dropout层，每次训练的时候随机选择一定的节点临时失效；</li>
<li>Embedding层，将输入的向量按照一定的规则改变维度；</li>
<li>Flatten层，将输入压平，多维输入一维化；</li>
<li>Permute层，将输入的维度按照给定模式进行重排；</li>
</ul>
<p>损失函数包括MSE、MAE、MAPE、MSLE、squared_hinge、hinge等，常用优化器为SGD、RMSprop、Adam等。</p>
<p>LSTM有通过精心设计的称作“门”的结构来去除或者增加信息到细胞状态的能力。门是一种让信息选择式通过的方法。</p>
<h2 id="二-强化学习"><a class="markdownIt-Anchor" href="#二-强化学习"></a> 二. 强化学习</h2>
<h3 id="1-单智力体强化学习"><a class="markdownIt-Anchor" href="#1-单智力体强化学习"></a> 1. 单智力体强化学习</h3>
<p>一个系统的状态的迁移变化，只与当前状态或者当前的N个状态有关，那么我们就称这个系统具有马尔可夫性。马尔可夫决策过程（Markov Decision Process, MDP）也具有马尔可夫性，并且MDP的状态迁移还与当前采取的动作有关。</p>
<div align="center">
  <img src="/2021/06/29/dou-brother/mdp.jpg" srcset="/img/loading.gif" width="30%" height="30%" alt="oauth">
</div>
<p>强化学习从MDP发展而来，包括Environment、Agent、Action、Observation和Reward。Agent在具体环境下基于一定的策略判断后执行动作，然后会得到环境的奖励并迁移到新的状态。Agent判断的策略是基于特定的状态s下，选择未来带来奖励最多的动作a，<strong>特定s和a下的代表未来的奖励称为Q函数</strong>，Q函数通常表示为Q(s, a)。</p>
<p>贪婪算法与<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi><mo>−</mo></mrow><annotation encoding="application/x-tex">\theta-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mord">−</span></span></span></span>贪婪算法、Sarse算法、Q-Learning算法（更新Q值的方法有所不同）、Deep Q Network（可以处理状态空间和动作空间为连续的情况）。DQN的核心思想：</p>
<ul>
<li>使用深度学习网络表示Q函数，训练的数据是状态s，训练的标签是状态s对应的每个动作的Q值，即标签是由Q值组成的向量，向量的长度与动作空间的长度相同。</li>
<li>动作选择的算法使用贪婪算法，其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span></span></span>可以是静态的也可以是随着时间动态变化的。</li>
<li>Q值的更新与Q Leaning算法相同</li>
<li>定义一段所谓的记忆体，在记忆体中保存具体某一时刻的当前状态、奖励、动作、迁移到的下一个状态、状态是否结束等信息，定期从记忆体中随机选择固定大小的一段记忆，用于训练深度神经网络。</li>
</ul>
<div align="center">
  <img src="/2021/06/29/dou-brother/rl.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<p>Keras-rl统一了智能体类的API，主要包括Fit、Test、compile（主要编译用户自定义的深度神经网络）函数。常用对象有记忆体SequentialMemory和选择策略Policy。</p>
<p>OpenAI Gym除了自己提供了机器人学任务、桌面游戏之类强化学习开发测试环境，还提供了一个非常简便的开发框架，便于大家开发自己的强化学习算法。这些环境都有一个通用交互界面，使用户能够编写可以应用于许多不同环境的通用算法。OpenAI Gym中包含一些经典的控制问题场景，比如独臂支撑（CartPole）、多连臂（Acrobot）和过山车（MountainCar）。</p>
<h2 id="三-恶意程序检测"><a class="markdownIt-Anchor" href="#三-恶意程序检测"></a> 三. 恶意程序检测</h2>
<h3 id="1-检测"><a class="markdownIt-Anchor" href="#1-检测"></a> 1. 检测</h3>
<p>代码参考了Endgame公司的开源实现（<a href="https://github.com/endgameinc/%EF%BC%89%E3%80%82" target="_blank" rel="noopener">https://github.com/endgameinc/）。</a></p>
<p>PE（Portable Executable）文件，意为可移植的、可执行的文件，常见的EXE、DLL、OCX、SYS、COM都是PE文件，PE文件是微软Windows操作系统上的可执行文件的标准格式。PE文件包括几个比较重要的部分，DOS头、文件头、可选头、数据目录，以及节头和节区。</p>
<p>特征提取方法总结《Deep Neural Network Based Malware Detection Using Two DimensionalBinary Program Features》。一类是通过PE文件可以直接获取到的特征，比如字节直方图，字节熵直方图和字符串特征等；另一类特征是需要解析PE文件结构，从各个节分析出的特征，比如节头特征，导入和导出表特征，文件头特征等。</p>
<p>numpy.bincount专门用于以字节为单位统计个数，minlength参数用于指定返回的统计数组的最小长度，不足最小长度的会自动补0。</p>
<p>单纯统计直方图<strong>非常容易过拟合</strong>，因为字节直方图对于PE文件的二进制特征过于依赖，PE文件增加一个无意义的0字节都会改变直方图。一种常见的处理方式是，增加一个维度的变量，用于统计PE文件的字节总数，同时原有直方图按照字节总数取平均值。</p>
<h3 id="2-免杀"><a class="markdownIt-Anchor" href="#2-免杀"></a> 2. 免杀</h3>
<p>LIEF是Library to Instrument Executable Formats的简称，它提供了跨平台解析和修改常见的可执行文件的能力。</p>
<p>对于依赖文件哈希值的杀毒软件，只需要在PE文件后面追加随机内容即可以绕过检测。为了更加逼真，还需要使用常见的库和导入函数来创建导入表。</p>
<p>修改已经存在的节的名称也可以迷惑杀毒软件，常见的方式是随机选择已经存在的节，并把节的名称修改为常见的节的名称。</p>
<p>增加新的节，节的名称既可以参考修改节名称的方式从常见的节名称中随机选择，也可以直接随机生成。</p>
<p><strong>加壳</strong>是名气最大的免杀方式，最入门级的工具是UPX。UPX的加壳过程可以分为两步：第一步，在PE文件的特定位置增加一段代码A；第二步，将代码段1、2和3无损压缩成代码段B，然后和代码段A一起组成新的程序。其中代码段A的主要功能是解压缩后面的代码段B。</p>
<p>杀毒软件无法根据签名和debug信息断定程序是否为恶意程序，但是攻击者却可以通过删除debug信息改变文件的哈希值和二进制特征。</p>
<p>将可选头的交验和设置为空也可以迷惑杀毒软件。</p>
<h3 id="3-智能提升"><a class="markdownIt-Anchor" href="#3-智能提升"></a> 3. 智能提升</h3>
<p>软件开发者通常他们会在写完程序后，使用常见的几种杀毒软件检测，如果被检测出来，就尝试使用不同的免杀技术直到杀毒软件无法检测为止。</p>
<p>2017年7月DEFCON，EndGame公司演示了<strong>使用机器学习创建恶意代码，从而绕过杀毒软件的检测</strong>。整个方案基于OpenAI Gym框架开发，称为Gym-Malware（<a href="https://github.com/endgameinc/gym-malware%EF%BC%89%E3%80%82%E4%BD%BF%E7%94%A8%E4%BA%86%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%96%B9%E5%BC%8F%EF%BC%8C%E9%80%9A%E8%BF%87%E8%87%AA%E5%8A%A8%E5%8C%96%E7%9A%84%E6%96%B9%E5%BC%8F%E5%B0%9D%E8%AF%95%E4%B8%8D%E5%90%8C%E5%85%8D%E6%9D%80%E6%96%B9%E6%B3%95%EF%BC%8C%E6%9C%80%E7%BB%88%E5%9C%A8%E4%B8%8E%E6%9D%80%E6%AF%92%E8%BD%AF%E4%BB%B6%E7%9A%84%E5%AF%B9%E6%8A%97%E4%B8%AD%E5%AD%A6%E4%B9%A0%E5%87%BA%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%85%8D%E6%9D%80%E6%81%B6%E6%84%8F%E8%BD%AF%E4%BB%B6%E3%80%82" target="_blank" rel="noopener">https://github.com/endgameinc/gym-malware）。使用了强化学习的方式，通过自动化的方式尝试不同免杀方法，最终在与杀毒软件的对抗中学习出如何生成免杀恶意软件。</a></p>
<div align="center">
  <img src="/2021/06/29/dou-brother/gymmal.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<p>PEFeatureExtractor的主要功能就是把PE文件转换成特征向量。Interface模块基于GBDT模型针对PE文件进行检测。MalwareManipulator模块封装了对PE文件的各种免杀操作。DQNAgent具体实现了强化学习算法。MalwareEnv对外主要提供了step和reset两个接口，Init函数主要负责创建MalwareEnv时完成一系列初始化工作，Step函数完成了最重要的动作执行、病毒检测以及反馈状态的功能，Reset函数负责重置环境的状态，并随机从样本中选择一个，转换成特征向量后作为初始状态。</p>
<h2 id="四-提升waf防护能力"><a class="markdownIt-Anchor" href="#四-提升waf防护能力"></a> 四. 提升WAF防护能力</h2>
<p>WAF的基本原理是，作为一道墙接受用户对Web服务器的请求，然后转发给后端真实的Web服务器，并将应答内容返回给用户。整个过程中，WAF针对请求和应答内容，按照既定的拦截规则进行过滤。</p>
<p>使用强化学习，模拟黑客的这一绕过思路，自动化地发现现有WAF的绕过方式，从而不断提升WAF的防护能力。</p>
<p>以XSS为例，有多种常见攻击方式和相应的检测方法。</p>
<p>常见的XSS绕过WAF的方式：</p>
<ul>
<li>16进制编码，浏览器可以正常解析，但是却可以绕过基于规则的WAF；</li>
<li>10进制编码</li>
<li>插入注释、回车、TAB</li>
<li>大小写混淆</li>
</ul>
<p>使用和恶意程序生成同样的框架完成这项工作。主要由DQNAgent, WafEnv_v0,Waf_Check, Xss_Manipulator和Features组成。Features将XSS样本转换成向量，Waf_Check基于规则用于XSS检测，XSS的特征向量作为状态传递。DQNAgent基于当前状态和一定的策略，选择免杀动作。WafEnv_v0根据免杀动作，通过Xss_Manipulator针对XSS样本执行免杀操作，然后使用Features重新计算特征，再使用Waf_Check判断，如果不是XSS，反馈10并结束本轮学习；如果是XSS，反馈0以及新状态给DQNAgent, DQNAgent继续选择下一步免杀操作，如此循环。（感觉整个过程并不是特别像强化学习，其实就是把各种免杀招数都用一用，智能化可能体现在有选择地使用）。</p>
<div align="center">
  <img src="/2021/06/29/dou-brother/xss.jpg" srcset="/img/loading.gif" width="50%" height="50%" alt="oauth">
</div>
<h2 id="五-提升垃圾邮件检测能力"><a class="markdownIt-Anchor" href="#五-提升垃圾邮件检测能力"></a> 五. 提升垃圾邮件检测能力</h2>
<p>一般的绕过可以通过随机增加TAB、回车、换行符、连字符，大小写混淆，使用错别字等方式实现。</p>
<p>整个系统的框架和上面相同。SpamEnv_v0类实现了强化学习中环境的主要功能，涉及的主要函数有Step和Reset。Step函数根据输入的动作动作序号，修改当前样本，再检测是否为垃圾邮件；Reset负责重置环境，从训练样本列表中随机选择一个作为当前样本并转换成对应的特征向量，作为初始状态。</p>
<h2 id="六-生成对抗网络"><a class="markdownIt-Anchor" href="#六-生成对抗网络"></a> 六. 生成对抗网络</h2>
<p>GAN包括噪音源、Generator和Discriminator，数据集包含真实样本即可。</p>
<p>常见的噪音就是分布满足<strong>平均分布和正态分布</strong>的随机数。</p>
<p>DCGAN，使用深度卷积神经网络作为图像识别和生成的工具。</p>
<p>ACGAN，基于分类优化的GAN（Auxiliary Classifier Generative Adversarial Network），在生成图像和进行图像分类的环节引入了图像内容的标签，所谓图像内容的标签。</p>
<p>WGAN，彻底解决了GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度，而且不需要精心设计的网络架构，不像DCGAN必须有BatchNormalization（批量正则化）。主要改进点在于：</p>
<ul>
<li>生成器和判别器的损失函数中不取log；</li>
<li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c；</li>
<li>优化算法使用RMSProp或者SGD；</li>
</ul>
<h2 id="七-攻击机器学习模型"><a class="markdownIt-Anchor" href="#七-攻击机器学习模型"></a> 七. 攻击机器学习模型</h2>
<p>常见图像分类算法有AlexNet、VGG16、ResNet50和InceptionV3。</p>
<p><strong>基于梯度上升的攻击原理</strong>：把图像分类抽象成一个二分类问题，通过微小改变特征的值，越过分割线，然后获得一个错误的分类结果。假如现在我们手上有一个家猪的照片，我们想伪造成烤面包机的照片，我们可以把损失函数定义为1减去烤面包机标签的概率，那么就可以使用梯度下降算法，或者把损失函数定义为烤面包机标签的概率，使用梯度上升算法，迭代调整图片的内容（也就是多维向量的数值）进行训练。常用方法FGSM（Fast Gradient Sign Method）。</p>
<p>强化学习模型也很脆弱，比如DQN、TRPO和A3C。《Vulnerability of Deep Reinforcement Learning to Policy InductionAttacks》</p>
<p>以MNIST手写字体识别为例，攻击CNN、自编码器、VAE等模型。</p>
<h1 id="ai安全之对抗样本入门"><a class="markdownIt-Anchor" href="#ai安全之对抗样本入门"></a> 《AI安全之对抗样本入门》</h1>
<p>这本书主要以图像识别、目标检测领域介绍对抗样本，和网络安全基本没有关系了。</p>
<h2 id="一-背景-2"><a class="markdownIt-Anchor" href="#一-背景-2"></a> 一. 背景</h2>
<p>百度AI模型安全的开源项目AdvBox（<a href="https://github.com/advboxes/AdvBox%EF%BC%89%EF%BC%8C%E7%B1%BB%E4%BC%BC%E7%9A%84%E6%A1%86%E6%9E%B6%E8%BF%98%E6%9C%89foolbox%E3%80%81adversarial-robustness-toolbox%E5%92%8Ccleverhans%E3%80%82" target="_blank" rel="noopener">https://github.com/advboxes/AdvBox），类似的框架还有foolbox、adversarial-robustness-toolbox和cleverhans。</a></p>
<p>深度学习的脆弱性主要体现在：偷取模型、数据投毒（攻击者把重点放到了在线学习的场景，比较典型的是推荐系统）、对抗样本（定向攻击和无定向攻击；黑盒、白盒、真实世界/物理攻击Real-world attack/ Physical attack）。</p>
<ul>
<li>White-Box Attack，攻击难度最低，前提是能够完整获取模型的结构，并且可以完整控制模型的输入。常见攻击方法如ILCM（最相似迭代）、FGSM（快速梯度）、BIM（基础迭代）、JSMA（显著图攻击）、DeepFool、C/W算法。</li>
<li>Black-BoxAttack完全把被攻击模型当成一个黑盒，对模型的结构没有了解，只能控制输入，通过比对输入和输出的反馈来进行下一步攻击。常见方法如单像素攻击、本地搜索攻击等。</li>
<li>Real-World Attack/Physical Attack是这三种攻击中难度最大的，除了不了解模型的结构，甚至对于输入的控制也很弱。</li>
</ul>
<p>常见的加固方法包括特征凝结（Feature squeezing）、空间平滑（Spatial smoothing）、标签平滑（Lable smoothing）、对抗训练、虚拟对抗训练、高斯数据增强等。</p>
<p>范数是一种强化了的距离概念，通常为了提高模型的抗过拟合能力而加入到损失函数中。</p>
<ul>
<li>L0范数，并不是一个真正的范数，它主要用于度量向量中非零元素的个数。对抗样本中通常指相对于原始图片修改的像素的个数。</li>
<li>L1范数，曼哈顿距离、最小绝对误差等，可以度量两个向量之间差异；</li>
<li>L2范数，欧氏距离就是一种L2范数；</li>
<li>无穷范数，主要用于度量向量元素的最大值；</li>
</ul>
<p>CNN之前图像分类算法依赖于复杂的特征工程，最常用SIFT、HOG、LBP等进行特征提取，常用分类算法是SVM。</p>
<p>常用CNN模型结构有AlexNet、VGG、ResNet50（残差结构）、InceptionV3（单层使用不同尺度的卷积核，基本单元为Inception）。</p>
<p>可视化CNN。使用一个卷积核处理图像数据后，卷积核会提取它关注的特征并形成新的图像，该图像也被称为<strong>特征图</strong>。可以基于梯度，<strong>迭代调整输入图像的值，让特征图的值最大化</strong>。当特征图的值达到最大或者迭代求解趋于稳定时，可以认为这时的输入图像就是该卷积核的可视化图像。</p>
<h2 id="二-图像处理基础"><a class="markdownIt-Anchor" href="#二-图像处理基础"></a> 二. 图像处理基础</h2>
<p>常用存储格式为BMP（与硬件无关的无损压缩格式）、JPEG（有损压缩）、GIF（基于LZW算法的连续色调无损压缩，压缩率在50%左右，可以存储多幅彩色图像形成动画）和PNG等。</p>
<p>CWH格式中C代表通道维度，W表示宽，H表示高。像素深度即表达一个像素点需要几位二进制数。</p>
<p>常见的图像转换包括缩放、旋转、剪切、平移、翻转、亮度与对比度，也叫作图像增强。</p>
<p>仿射变换（Affine Transformation）是空间直角坐标系的变换，从一个二维坐标变换到另一个二维坐标，比较常用的变换有缩放、旋转、平移、剪切和翻转。仿射变换是一个线性变换，它保持了图像的“平行性”和“平直性”，即图像中原来的直线和平行线，变换后仍然保持原来的直线和平行线。可通过OpenCV中的warpAffine函数实现。</p>
<p>常见的图像噪声是<strong>高斯噪声和椒盐噪声</strong>。一种是盐噪声（Salt noise），另一种是胡椒噪声（Pepper noise）。盐噪声为白色，胡椒噪声为黑色。可以使用skimage库给图像添加噪声。</p>
<p>滤波可以去噪，<strong>中值滤波</strong>使用邻域内所有像素的中位数替换中心像素的值，可以在滤除异常值的情况下较好地保留纹理信息。<strong>均值滤波</strong>不能很好地保护图像细节，在图像去噪的同时也破坏了图像的细节部分，从而使图像变得模糊。均值滤波和中值滤波的效果非常接近。高斯滤波使用邻域内所有像素的加权平均值替换中心像素的值。<strong>高斯滤波</strong>适用于消除高斯噪声，广泛应用于图像处理的减噪过程。<strong>高斯双边滤波</strong>同时考虑空间域和值域，是结合图像的空间邻近度和像素值相似度的一种折中处理，达到保护边缘并去除噪声的目的（保边去噪）。</p>
<h2 id="三-攻击方法"><a class="markdownIt-Anchor" href="#三-攻击方法"></a> 三. 攻击方法</h2>
<h3 id="1-白盒"><a class="markdownIt-Anchor" href="#1-白盒"></a> 1. 白盒</h3>
<p>重点介绍基于梯度的对抗样本生成算法，其中比较基础的关键概念如下：</p>
<ul>
<li>Method，攻击算法</li>
<li>Black/white，是黑盒还是白盒</li>
<li>Targeted/Non-targeted，定向攻击还是非定向攻击；</li>
<li>Image-specific/universal，是否具有通用性，前者针对不同图片生成不同对抗样本，后者表示通用对抗扰动；</li>
<li>Perturbation norm，算法支持的范数</li>
<li>Learning，算法是基于迭代优化的还是一步操作就可以完成的；</li>
<li>Strength，算法的攻击强度，即攻击成功率。</li>
</ul>
<h4 id="fgmfgsm算法"><a class="markdownIt-Anchor" href="#fgmfgsm算法"></a> FGM/FGSM算法</h4>
<p>快速梯度算法《Explaining and Harnessing Adversarial Examples》，支持无定向和定向攻击。</p>
<h4 id="deepfool算法"><a class="markdownIt-Anchor" href="#deepfool算法"></a> DeepFool算法</h4>
<p>《DeepFool：a simple and accurate method tofool deep neural networks》，通常无定向，相对FGM而言，不用指定学习速率ε，算法本身可以计算出相对FGM更小的扰动来达到攻击目的。</p>
<h4 id="jsma算法"><a class="markdownIt-Anchor" href="#jsma算法"></a> JSMA算法</h4>
<p>《The Limitations of Deep Learning in Adversarial Settings》典型的l0范数的白盒定向攻击算法，追求的是尽量减少修改的像素个数。引入了<strong>Saliency Map即显著图</strong>的概念，用以表征输入特征对预测结果的影响程度。</p>
<h4 id="cw算法"><a class="markdownIt-Anchor" href="#cw算法"></a> CW算法</h4>
<p>《Towards Evaluating theRobustness of Neural Networks》，攻击能力最强的白盒算法之一，是一种基于优化的算法。同时支持l0、l2和l∞攻击。CW算法的一个核心点就是通过二分查找计算出尽量小的c值。另外一个特色就是对数据截断的处理（Projected gradient descent，即梯度投影下降、Clipped gradient descent，即梯度截断下降）。</p>
<h3 id="2-黑盒"><a class="markdownIt-Anchor" href="#2-黑盒"></a> 2. 黑盒</h3>
<p>目前常见的黑盒攻击算法主要分为两类，<strong>一类是基于一定的算法构造输入</strong>，然后根据模型的反馈不断迭代修改输入，比较典型的就是单像素攻击算法和本地搜索攻击算法；<strong>另一类是基于迁移学习的思想</strong>，使用与白盒攻击类似的开源模型，之后用生成的攻击样本进行黑盒攻击。</p>
<h4 id="单像素攻击算法"><a class="markdownIt-Anchor" href="#单像素攻击算法"></a> 单像素攻击算法</h4>
<p>《Simple Black-Box AdversarialPerturbations for Deep Networks》</p>
<p>AdvBox和Foolbox均实现了这个算法。</p>
<h4 id="本地搜索攻击算法"><a class="markdownIt-Anchor" href="#本地搜索攻击算法"></a> 本地搜索攻击算法</h4>
<p>当图像较大时，一个像素点的改变很难影响到分类结果。并且随着图像文件的增大，搜索空间也迅速增大，单像素攻击的效率也会快速下降。</p>
<p>《Simple Black-Box Adversarial Perturbations for Deep Networks》</p>
<p>单像素攻击算法没有很好地利用模型的反馈信息去优化扰动，很大程度上依赖随机选择像素和迭代调整像素点的值。本地搜索攻击算法的主要改进点就是<strong>根据模型的反馈信息去选择扰动的点</strong>，并随机选择对分类结果影响大的点周围的点，进一步进行选择。</p>
<h4 id="迁移学习攻击"><a class="markdownIt-Anchor" href="#迁移学习攻击"></a> 迁移学习攻击</h4>
<p>基本思想是，结构类似的深度学习网络，在面对相同的对抗样本的攻击时，具有类似的表现。</p>
<p>对抗样本在不同算法之间有一定的迁移性，或者称<strong>对抗样本的传递性</strong>。虽然基于对抗样本的传递性可以构造出对抗样本，但是成功率并不能令人满意。基于此，Yanpei Liu、Xinyun Chen和Dawn Song等人提出了<strong>对抗样本领域的集成学习的方法</strong>，以多个深度神经网络模型为基础构造对抗样本。</p>
<h4 id="universal对抗样本"><a class="markdownIt-Anchor" href="#universal对抗样本"></a> Universal对抗样本</h4>
<p>通用对抗样本事实上是一类精心构造的扰动，具有通用性，而且可以足够小，所以也被称为通用对抗扰动。</p>
<p>通用对抗扰动的获取是一个迭代求解的过程，通常需要准备一份测试数据，该测试数据需要覆盖全部分类类型，并且尽可能使各个分类的数量都比较均匀。</p>
<h2 id="四-目标检测领域"><a class="markdownIt-Anchor" href="#四-目标检测领域"></a> 四. 目标检测领域</h2>
<p>在无人驾驶领域的应用场景比如车道偏离预警、前方防碰撞预警、交通标志识别、行人防碰撞、疲劳驾驶检测预警、自动泊车等。</p>
<p>在智能安防领域的场景比如，人脸检索、行为识别。</p>
<p>边缘检测（soble，拉普拉斯，Canny，），直线检测、圆形检测等。</p>
<p>目标检测领域常用概念如下：</p>
<ul>
<li>Region Proposals，推荐框，在图片中识别出物体的轮廓，并用一个长方形表示物体的范围；</li>
<li>Ground Truth，标定过的真实数据，即人工标记的物体的真实范围；</li>
<li>IoU，系统预测出来的与原来图片中标记的框的重合程度；</li>
</ul>
<p>Faster RCNN是经典的目标检测算法，由RCNN、Fast RCNN演变而来。RCNN最花费时间的阶段就是要针对每个Region Proposals经过CNN计算，FastRCNN创新地把CNN阶段提前，整张图片仅进行一次CNN计算，然后再计算Region Proposals。</p>
<p>YOLO算法全称You Only look Once Detector，是一个可以一次性预测多个检测框位置和类别的卷积神经网络，能够实现端到端的目标检测和识别，其最大的优势就是速度快。YOLO有众多版本，其中最著名是<strong>YOLO V3</strong>。</p>
<p>SSD算法全称Single Shot MultiBox Detector，是主流检测框架之一，相比Faster RCNN有明显的速度优势，相比YOLO又有明显的mAP优势。主要特点如下：</p>
<ul>
<li>从YOLO中继承了将检测问题转化为回归问题的思路，同时一次即可完成网络训练；</li>
<li>基于Faster RCNN中的anchor，提出相似的prior box；</li>
<li>加入基于特征金字塔的检测方式；</li>
</ul>
<h2 id="五-常见防御算法"><a class="markdownIt-Anchor" href="#五-常见防御算法"></a> 五. 常见防御算法</h2>
<p>图片旋转、滤波器、亮度和对比度、噪声等都会对模型鲁棒性产生影响。</p>
<p>常见的防御措施包括图像预处理，在具体的参数，比如旋转的角度、滤波器的设置等要根据实际的模型和数据集进行优化调整。</p>
<p>对抗训练，可以首先使用常见的对抗样本算法，针对被攻击模型生成大量的对抗样本，然后把对抗样本和原始数据放到模型里重新训练，进行有监督学习，这样就获得了加固后的模型。</p>
<p>高斯数据增强，算法认为绝大多数的对抗样本相当于在原始图像上叠加了噪声，理想情况下可以用高斯噪声模拟这种噪声。</p>
<p>自编码器去噪，输入层和输出层分别代表神经网络的输入层和输出层，隐藏层承担编码器和解码器的工作，编码的过程就是从高维度的输入层转化到低维度的隐藏层的过程，反之，解码过程就是低维度的隐藏层到高维度的输出层的转化过程，可见自编码器是个有损转化的过程，通过对比输入和输出的差别来定义损失函数。</p>
<p>训练的过程不需要对数据进行标记。</p>
<p>自编码器通过学习数据集自身的特征，在一定程度上能过滤掉叠加到原始数据上的不规则的噪音。</p>
<p>大多数白盒攻击通过计算模型的梯度来运行，因此如果不能通过计算得到有效的梯度，那么攻击就会失效。<strong>梯度掩蔽</strong>通过在某种程度上改变模型，使其不可微分，或者使其在大多数情况下具有零梯度，或者梯度点远离决策边界。此后研究者应用新开发的攻击技术，解决了梯度掩蔽问题。（<a href="https://github.com/anishathalye/obfuscated-gradients%EF%BC%89" target="_blank" rel="noopener">https://github.com/anishathalye/obfuscated-gradients）</a></p>
<h2 id="六-常见工具箱"><a class="markdownIt-Anchor" href="#六-常见工具箱"></a> 六. 常见工具箱</h2>
<p>包括AdvBox、ART、FoolBox和Cleverhans等。</p>
<p>对抗样本质量衡量指标包括攻击成功率、扰动的L0、L2、Linf范数。</p>
<ul>
<li>AdvBox是一款由百度安全实验室研发，在百度大范围使用的AI模型安全工具箱，目前原生支持PaddlePaddle、PyTorch、Caffe2、MXNet、Keras以及TensorFlow平台，同时支持GraphPipe，屏蔽了底层使用的深度学习平台。</li>
<li>ART（Adversarial Robustness Toolbox）是IBM研究团队开源的用于检测模型及对抗攻击的工具箱。</li>
<li>FoolBox由Bethge Lab[插图]的三名德国科学家开发，能够帮助用户在解析“黑匣子”时更轻松地构建起攻击模型，并且在名人面部识别与高知名度Logo识别方面成功骗过美国热门的图片识别工具。</li>
<li>Cleverhans是用于对机器学习模型进行对抗性攻击、防御和基准测试的Python库。</li>
<li>robust-ml[插图]是一个轻量级的攻防对抗环境，可以很方便地在ImageNet 2012这样的大型数据集上验证白盒攻击或者防御算法的有效性。</li>
</ul>
<p>GraphPipe是甲骨文开源的通用深度学习模型部署框架。官方对GraphPipe的定义为，这是一种协议和软件集合，旨在简化机器学习模型部署并将其与特定于框架的模型实现分离。</p>
<p>ONNX（Open Neural Network Exchange）[插图]，即开放的神经网络切换。顾名思义，该项目的目的是让不同的神经网络开发框架做到互通互用。开发者能更方便地在不同框架间切换，为不同任务选择最优工具。</p>
<p>NIPS对抗攻击防御是由Ian Goodfellow牵头组织的对抗样本领域顶级竞赛，包括无目标对抗攻击、有目标对抗攻击和针对对抗攻击的防御。</p>
<h1 id="其它记录"><a class="markdownIt-Anchor" href="#其它记录"></a> 其它记录</h1>
<p>2015年，微软在Kaggle上发起了一个恶意代码分类比赛，提供超过500G的原始数据，冠军队伍选择了三个黄金特征：恶意代码图像（二进制文件灰度图）、OpCode n-gram和Headers个数，其它包括ByteCode n-gram，指令频数等，机器学习选择了随机森林算法并用到XGBoost和pypy加快训练速度。</p>
<p>百度王磊团队，《AI Based Antivirus∶ Can Alphaav Win The Battle in Which Man HasFailed?》对APK提取三大类特征：</p>
<ul>
<li>结构化特征，APK申请的权限的个数，资源文件中包含的图像文件个数和参数大于20的函数的个数等；</li>
<li>统计类特征</li>
<li>经验特征，资源文件中是否包含可执行文件，assets文件夹中是否包含APK文件等；</li>
</ul>
<h3 id="一些文件操作"><a class="markdownIt-Anchor" href="#一些文件操作"></a> 一些文件操作</h3>
<pre><code class="hljs python"><span class="hljs-comment"># 递归遍历目录下文件的函数</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dirlist</span><span class="hljs-params">(path, allfile)</span>:</span>
    filelist = os.listdir(path)
    <span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> filelist:
        filepath = os.path.join(path, filename)
        <span class="hljs-keyword">if</span> os.path.isdir(filepath):
            dirlist(filepath, allfile)
        <span class="hljs-keyword">else</span>:
            allfile.append(filepath)
    <span class="hljs-keyword">return</span> allfile

<span class="hljs-comment"># 按后缀名筛选</span>
file.endswith(<span class="hljs-string">'.php'</span>)

<span class="hljs-comment">#pickle.dump保存、加载中间结果</span>
pickle.dump(char_idx, open(cahr_idx_file,<span class="hljs-string">'wb'</span>))
<span class="hljs-keyword">if</span> os.path.isfile(char_idx_file):
    print(<span class="hljs-string">'Loading previsou file'</span>)
    char_idx = pickle.load(open(char_idx_file, <span class="hljs-string">'rb'</span>))
    
<span class="hljs-comment"># 统计个数</span>
np.bincount(np.array([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">7</span>]))</code></pre>
<p>urlparse.parse_qsl解析url请求切割参数时，遇到’; ‘会截断，导致获取的参数值缺失’; '后面的内容，这是个大坑。</p>
<p>tensorflow提供API支持char_idx结构定义的转换关系。temperature可以理解为新颖程度，越小生成序列就越接近于原有序列。</p>
<p>Opcode是计算机指令中的一部分，用于指定要执行的操作，指令的格式和规范由处理器的指令规范指定。通常opcode还有另一种称谓——字节码（bytecodes）。opcode缓存技术[插图]可以有效减少不必要的编译步骤，减少CPU和内存的消耗。</p>
<p>Scikit-Learn的GridSearchCV模块，能够在指定的范围内自动搜索具有不同超参数的不同模型组合，大大提高了我们的参数优化效率。</p>
<p>Python的<strong>pickle模块</strong>实现了基本的数据序列和反序列化。通过pickle模块的序列化操作，我们能够将程序中运行的对象信息保存到文件中永久存储，通过pickle模块的反序列化操作，我们能够从文件中创建上一次程序保存的对象。通常持久化的文件后缀为．pkl或者．pickle，使用joblib可以很方便地把模型保存成文件或者从文件中加载模型。</p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">读书笔记</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/">网络安全</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2021/07/01/fl/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">联邦学习基础知识梳理</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2021/06/29/lhy-hw/">
                        <span class="hidden-mobile">lhy_hw</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    function loadGitalk(){
      addScript('https://cdn.staticfile.org/gitalk/1.6.2/gitalk.min.js', function () {
        var gitalk = new Gitalk({
          clientID: '719893e76127bcc98b08',
          clientSecret: 'ed167d3d935e2922b47f190e1f36b026bd823a2d',
          repo: 'deepdeer.github.io',
          owner: 'DeepDeer',
          admin: 'DeepDeer',
          id: location.pathname,
          language: 'zh-CN',
          perPage: 15,
          pagerDirection: 'last',
          createIssueManually: 'false',
          distractionFreeMode: 'false'
        });
        gitalk.render('gitalk-container');
      });
    }
    createObserver(loadGitalk, 'gitalk-container');
  </script>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>




















</body>
</html>
